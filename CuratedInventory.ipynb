{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Longitudinal Visit Inventory - curated data\n",
    "#!pip install pandas\n",
    "\n",
    "##MOST OF THE Things you'll find here are exceptions to deal with widely varying user-determined conventions across data types and sources\n",
    "\n",
    "## No way to prevent much of the hardcoded mess of this code other than to forbid excel spreadsheets in BOX and have a single database of everything (impossible)\n",
    "# and a usable 'patch' system in the visit summary with which to capture deviations systematically.\n",
    "\n",
    "##NOTE THAT SINCE Q and KSADS no longer reside in their REDCap databases, their respective inventory \n",
    "# components/cleaning  generation codes have  \n",
    "#have been commented out.  Their values are unchanged though, so they are just merged back in from an old version of the inventory.\n",
    "\n",
    "# Two CC subects added since some usable imaging and behavioral data before visit and didn't come back\n",
    "\n",
    "# The rest of the CC data were either exluded in favor of later comprehensive data (e.g. everything recollected after covid)\n",
    "# or excluded completely.  \n",
    "# only a small handful of subjects ~10 affected.  See Universe Inventory for details. (Sandy, Erin, IntraDB, Behavioral)\n",
    "\n",
    "# HCA9461182 V2 needs to be removed from curated, due to informed consent concerns (behavioral only)\n",
    "# only redcap_event=V2 is affected.  All other events (CR, etc) happened before V2\n",
    "\n",
    "# this subject is not be flagged as usual because subject id will not contain _withdrawn in REDCap.  \n",
    "# new release of HCA data will need to make sure this suject has no v2 data released\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import json\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import pycurl\n",
    "from io import BytesIO #, cStringIO\n",
    "import yaml\n",
    "\n",
    "##from config import config\n",
    "#from ccf.redcap import RedcapTable\n",
    "from ccf.box import LifespanBox\n",
    "##from ccf.easy_yaml import EasyYaml\n",
    "\n",
    "##from download.redcap import Redcap\n",
    "#from download.box import LifespanBox\n",
    "snapshotdate = datetime.datetime.today().strftime('%m_%d_%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_cache = '/home/petra/Behavioral/Lifespan/PreRelease/PreRelease/cache'\n",
    "cache_space = os.path.join(root_cache, 'inventory')\n",
    "try:\n",
    "    os.mkdir(cache_space)\n",
    "except BaseException:\n",
    "    print(\"cache already exists\")\n",
    "    \n",
    "root_store = '/home/petra/Behavioral/Lifespan/PreRelease/PreRelease'\n",
    "# this will be the place to save any snapshots on the nrg servers\n",
    "store_space = os.path.join(root_store, 'penncnp')\n",
    "try:\n",
    "    os.mkdir(store_space)  # look for store space before creating it here\n",
    "except BaseException:\n",
    "    print(\"store already exists\")\n",
    "\n",
    "# connect to Box\n",
    "box = LifespanBox(cache=cache_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curated pedigrees (created after iterating over questions from double winners and observed subjects)\n",
    "#...has been reconciled with double winners and final tallies and contains redundant information with inventory.\n",
    "# Just grab pedids.\n",
    "\n",
    "peds=885490766829\n",
    "pathpeds=box.downloadFile(peds)\n",
    "pedids=pd.read_csv(pathpeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pedids.columns)\n",
    "pedids.head\n",
    "pedfinal=pedids[['pedid','psuedo_guid']].copy() #spellcheck for psue vs pseu will happen later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get double winners\n",
    "fams = 325108125732\n",
    "pathdd = box.downloadFile(fams)\n",
    "doubles=pd.read_excel(pathdd,'HCP Participants - Multiple IDs')\n",
    "doubles.head()\n",
    "print(doubles.shape)\n",
    "doubles=doubles.loc[~(doubles['Subject ID2']=='HCA6780082')]# not actually a double winner...per trello - a DART flub\n",
    "\n",
    "#HCD3429964 was parent of dnr subject\n",
    "doubles['Subject ID2']=doubles['Subject ID2'].str.strip()\n",
    "doubles['Subject ID1']=doubles['Subject ID1'].str.strip()\n",
    "\n",
    "notdoubs=['HCD5337666','HCA7263774','HCA9377092','HCA6133453','HCA8091675',\n",
    "          'HCD5320952','HCD5681681','HCD5561570','HCD3429964','HCA7181873']\n",
    "doubles=doubles.loc[~(doubles['Subject ID2'].isin(notdoubs))]\n",
    "doubles=doubles.loc[~(doubles['Subject ID1'].isin(notdoubs))]\n",
    "\n",
    "doubles['Subject ID2']=doubles['Subject ID2'].str.strip()\n",
    "doubles['Subject ID1']=doubles['Subject ID1'].str.strip()\n",
    "\n",
    "\n",
    "print(doubles.shape)\n",
    "\n",
    "#get pedids\n",
    "print(pathdd)\n",
    "#doubles\n",
    "#doubles.loc[doubles['Subject ID2']=='HCA6673990']\n",
    "doubles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles['HCAid']=''\n",
    "doubles['HCDid']=''\n",
    "doubles.loc[doubles['Subject ID1'].str.contains('HCA'),'HCAid']=doubles['Subject ID1']\n",
    "doubles.loc[doubles['Subject ID2'].str.contains('HCA'),'HCAid']=doubles['Subject ID2']\n",
    "doubles.loc[doubles['Subject ID1'].str.contains('HCD'),'HCDid']=doubles['Subject ID1']\n",
    "doubles.loc[doubles['Subject ID2'].str.contains('HCD'),'HCDid']=doubles['Subject ID2']\n",
    "\n",
    "doubles[['HCAid','HCDid']]\n",
    "doubles=doubles.loc[~(doubles.HCAid=='')][['HCAid','HCDid']]\n",
    "#doubles.loc[doubles.HCDid=='']\n",
    "doubles.head()\n",
    "test=pd.DataFrame(doubles.groupby('HCAid').count())\n",
    "test.loc[test.HCDid>1]\n",
    "doubles.loc[doubles.HCAid=='HCA8655796']\n",
    "print(doubles.shape)\n",
    "doubles=doubles.drop_duplicates()\n",
    "print(doubles.shape)\n",
    "\n",
    "\n",
    "#doubles.loc[doubles['HCAid'].isin(['HCA8455687','HCA6673990','HCA7222558','HCA9105362'])]\n",
    "doubles.loc[doubles['HCAid'].isin(['HCA6430257','HCA7181873','HCA6197580','HCD4248763'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Penn, TOOLBOX and eprime curated data (e.g. data curated in BOX)\n",
    "\n",
    "#PENN\n",
    "boxfile = 452784840845\n",
    "path = box.downloadFile(boxfile)\n",
    "rows = pd.read_csv(path,encoding = \"ISO-8859-1\")\n",
    "\n",
    "#PENN HCA and HCD\n",
    "print(rows.shape)\n",
    "rows=rows.loc[~(rows.p_unusable==1.0)]\n",
    "print(rows.shape)\n",
    "rows=rows.loc[~(rows.CC==\"_CC\")]\n",
    "print(rows.shape)\n",
    "\n",
    "rows.groupby('p_unusable').count()\n",
    "pennHCA=rows.loc[rows.subid.str.contains('HCA')][['subid','assessment']]\n",
    "pennHCA.head()\n",
    "pennHCD=rows.loc[rows.subid.str.contains('HCD')][['subid','assessment']]\n",
    "pennHCA.head()\n",
    "print(\"Curated PennHCA has duplicates:\")\n",
    "print(pennHCA.loc[pennHCA.duplicated()]) #should be empty\n",
    "pennHCA=pennHCA.drop_duplicates()\n",
    "\n",
    "#eprime\n",
    "efile=495490047901\n",
    "epath=box.downloadFile(efile)\n",
    "erows = pd.read_csv(epath)\n",
    "erows.head()\n",
    "#print(erows.shape)\n",
    "erows=erows.loc[~(erows.exclude==1)]\n",
    "#print(erows.shape)\n",
    "erows=erows.loc[~(erows.CC==\"_CC\")][['subject','visit']]\n",
    "#print(erows.columns)\n",
    "print(\"Curated EprimeHCA has duplicates:\")\n",
    "print(erows.loc[erows.duplicated()]) #should be empty\n",
    "\n",
    "\n",
    "###TOOLBOX general - note that this is pooled snapshot of site specific folders\n",
    "hcascoresfile = 882674939560 #11/8/2021#880673383760 #877221666211 10/20/21 #862811991011 9/21/21 #857396266421 9/8b  #854463176423 9/1/2021 #853936863760 8/30/2021 #851759160729 8/26/21 #851264296869 8/25/2021 #851206802523 8/25/2021 #841438907370 7/30/2021 #840036292919 7/29/2021 #839520151647 7/28/21 #827891911711 #6/29/2021 #827818457955 6/28/2021 #820198815649 6/7/2021  #818565674663 6/3/2021 #812156608179 5/18/21 #810562627342 5/12b # 807069868654 5/3/2021 #800335923007  4/16/2021 #798649192122 4/9/21 snapshot   #790168415847 3/22/21 snapshot\n",
    "hcdscoresfile = 882674462555 #11/8/2021 #880673591992 #877219908449 10/20/21 #862815084330 9/21 #857399575337 9/8b #854461661743 9/1/2021 #853938817530 8/30/2021 #851755190211 8/26/21 #851245660414 8/25/2021 #851203289230 8/25/2021 #841449889601 7/30/2021 #840032080204 7/29/2021 #839517147786 7/28/21 #827893157067 6/29/2021 #827817995106 6/28/2021 #820198162992 6/7/2021  #818566872597 6/3/2021 #812156994062 5/18/21 #810564435127 5/12b # 807058665929  5/3/2021 # 800335359251  4/16/2021 #798650444849 4/9/21 snapshot   #790168329395  3/22/21 snapshot\n",
    "hcapath = box.downloadFile(hcascoresfile)\n",
    "rowshca = pd.read_csv(hcapath,low_memory=False)\n",
    "hcdpath = box.downloadFile(hcdscoresfile)\n",
    "rowshcd = pd.read_csv(hcdpath,low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doubles.head()\n",
    "pennHCA.head()\n",
    "erows.head()\n",
    "rows.groupby('p_unusable').count()\n",
    "print(pennHCA.loc[pennHCA.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pennHCA.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TLBX HCA stuff\n",
    "a=rowshca[['PIN','DateFinished']] #date will be necessary for HCD parents and mapping to specific children\n",
    "a=a.sort_values(by=['PIN','DateFinished'])#,ascending=False)\n",
    "a=a.drop_duplicates(subset=['PIN']).copy()\n",
    "print(len(a.PIN.unique()))\n",
    "a.loc[a.DateFinished.isnull()==True].shape\n",
    "\n",
    "new = a['PIN'].str.split(\"_\", 1, expand=True)\n",
    "a['subject'] = new[0].str.strip()\n",
    "a['event'] = new[1].str.strip()\n",
    "a['subjectlength']=a.subject.str.len()\n",
    "a.loc[a.subjectlength>10] #none, whew\n",
    "print(a.groupby('event').count())\n",
    "#trello, then drop anything that isn't clear\n",
    "#a=a.loc[~(a.event=='V1_A')]\n",
    "#a.groupby('event').count()\n",
    "TLBXA=a[['subject','event','DateFinished']].copy()\n",
    "TLBXA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TLBX HCD stuff\n",
    "d=rowshcd[['PIN','DateFinished']] #date will be necessary for HCD parents and mapping to specific children\n",
    "d=d.sort_values(by=['PIN','DateFinished'])#,ascending=False) #need to sort so you get the non missing date (composite scores have no date)\n",
    "d=d.drop_duplicates(subset='PIN').copy()\n",
    "d.loc[d.DateFinished.isnull()==True].shape\n",
    "\n",
    "\n",
    "d.PIN=d.PIN.str.upper()\n",
    "new = d['PIN'].str.split(\"_\", 1, expand=True)\n",
    "d['subject'] = new[0].str.strip()\n",
    "d['event'] = new[1].str.strip()\n",
    "d['subjectlength']=d.subject.str.len()\n",
    "d.loc[d.subjectlength>10] #none, whew\n",
    "\n",
    "\n",
    "print(d.groupby('event').count())\n",
    "Xlist=d.loc[d.event.str.contains('X')].copy() #[['PIN']] #this is a Harvard record...not wrong but will need to be added to\n",
    "##inventory by hand along with the rest of the X round ups.  see later cell...\n",
    "##drop anything that isn't clearly associated with an event\n",
    "print(Xlist)\n",
    "d=d.loc[~(d.event.isin(['V1_A','V2_X','X1','X2']))]\n",
    "d.groupby('event').count()\n",
    "TLBXD=d[['subject','event','DateFinished']].copy()\n",
    "TLBXD.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q, SSAGA, KSADS and other REDCap curated data\n",
    "with open('secrets.yaml') as f:\n",
    "    dict = yaml.load(f,Loader=yaml.FullLoader)\n",
    "    #print(dict)\n",
    "\n",
    "keys=pd.DataFrame(dict[\"redcaps\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longitudinal REDCap report grabs (configuration and functions for grabs that happen 2 cells from now)\n",
    "datahcpa = {\n",
    "    'token': keys.loc[keys.source=='hcpa','apikey'].reset_index()['apikey'][0],\n",
    "    'content': 'report',\n",
    "    'format': 'json',\n",
    "    'report_id': '46800',\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'returnFormat': 'json'\n",
    "}\n",
    "datachild = {\n",
    "    'token': keys.loc[keys.source=='child','apikey'].reset_index()['apikey'][0],\n",
    "    'content': 'report',\n",
    "    'format': 'json',\n",
    "    'report_id': '46829',\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'returnFormat': 'json'\n",
    "}\n",
    "dataparents = {\n",
    "    'token': keys.loc[keys.source=='parents','apikey'].reset_index()['apikey'][0],\n",
    "    'content': 'report',\n",
    "    'format': 'json',\n",
    "    'report_id': '46834',\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'returnFormat': 'json'\n",
    "}\n",
    "data18 = {\n",
    "    'token': keys.loc[keys.source=='teen','apikey'].reset_index()['apikey'][0],\n",
    "    'content': 'report',\n",
    "    'format': 'json',\n",
    "    'report_id': '46835',\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'returnFormat': 'json'\n",
    "}\n",
    "\n",
    "dataQ = {\n",
    "    'token': '782B7E6508132C0F26CF8C7CD7138D7C', # keys.loc[keys.source=='q','apikey'].reset_index()['apikey'][0],\n",
    "    'content': 'report',\n",
    "    'format': 'json',\n",
    "    'report_id': '37796',\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'returnFormat': 'json'\n",
    "}\n",
    "\n",
    "dataSSAGA = {\n",
    "    'token': keys.loc[keys.source=='ssaga','apikey'].reset_index()['apikey'][0],\n",
    "    'content': 'report',\n",
    "    'format': 'json',\n",
    "    'report_id': '47699',\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'returnFormat': 'json'\n",
    "}\n",
    "\n",
    "dataKSADS = {\n",
    "    'token': keys.loc[keys.source=='ksads','apikey'].reset_index()['apikey'][0],\n",
    "    'content': 'report',\n",
    "    'format': 'json',\n",
    "    'report_id': '38258',\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'returnFormat': 'json'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getreport(data=datahcpa):\n",
    "    buf = BytesIO()\n",
    "    ch = pycurl.Curl()\n",
    "    ch.setopt(ch.URL, 'https://redcap.wustl.edu/redcap/srvrs/prod_v3_1_0_001/redcap/api/')\n",
    "    ch.setopt(ch.HTTPPOST, list(data.items()))\n",
    "    ch.setopt(ch.WRITEDATA, buf)\n",
    "    ch.setopt(pycurl.SSL_VERIFYPEER, 0)   \n",
    "    ch.setopt(pycurl.SSL_VERIFYHOST, 0)\n",
    "    ch.perform()\n",
    "    ch.close()\n",
    "    htmlString = buf.getvalue().decode('UTF-8')\n",
    "    #print buf.getvalue()\n",
    "    buf.close()\n",
    "    HCA_json=json.loads(htmlString)\n",
    "    HCAdf=pd.DataFrame(HCA_json)\n",
    "    HCAdf = HCAdf.reindex(columns=list(HCA_json[0].keys()))\n",
    "    HCAdf.head()\n",
    "    return HCAdf\n",
    "\n",
    "def getreport9(data=datahcpa):\n",
    "    buf = BytesIO()\n",
    "    ch = pycurl.Curl()\n",
    "    ch.setopt(ch.URL, 'https://redcap.wustl.edu/redcap/api/')\n",
    "    ch.setopt(pycurl.SSL_VERIFYPEER, 0)   \n",
    "    ch.setopt(pycurl.SSL_VERIFYHOST, 0)\n",
    "    ch.setopt(ch.HTTPPOST, list(data.items()))\n",
    "    ch.setopt(ch.WRITEDATA, buf)\n",
    "    ch.perform()\n",
    "    ch.close()\n",
    "    htmlString = buf.getvalue().decode('UTF-8')\n",
    "    #print buf.getvalue()\n",
    "    buf.close()\n",
    "    HCA_json=json.loads(htmlString)\n",
    "    HCAdf=pd.DataFrame(HCA_json)\n",
    "    HCAdf = HCAdf.reindex(columns=list(HCA_json[0].keys()))\n",
    "    HCAdf.head()\n",
    "    return HCAdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only the usable records (e.g. filter for withdrawns or known empty files or duplicated records that need to be tracked)\n",
    "#report any newly identified issues to sites after searching for open trello cards\n",
    "#tempQ='/home/petra/UbWinSharedSpace1/boxtemp/QInteractive-Subjectsandvisits_DATA_2021-11-03_1151.csv'\n",
    "#tempK='/home/petra/UbWinSharedSpace1/boxtemp/KSADSv2-Commonform_DATA_2021-11-03_1124.csv'\n",
    "#tempS='/home/petra/UbWinSharedSpace1/boxtemp/SSAGA_DATA_2021-11-03_1545.csv'\n",
    "###ADD CHECKS FOR DUPLICATES AND BAD IDS FOR SETTING TO UNUSABLE IN CURATED LOCATION, NOW THAT INVENTORIES HAVE BEEN MERGED\n",
    "###AND NO LONGER USING OLD QC CODES.\n",
    "\n",
    "Qdf=getreport9(data=dataQ)\n",
    "#Qdf=pd.read_csv(tempQ)\n",
    "print(Qdf.shape)\n",
    "Qdf=Qdf.loc[~(Qdf.q_unusable=='1')][['subjectid', 'visit']]\n",
    "#Qdf=Qdf.loc[~(Qdf.q_unusable==1)][['subjectid', 'visit']]\n",
    "print(Qdf.shape)\n",
    "Qdf=Qdf.loc[~(Qdf.subjectid.str.upper().str.contains(\"CC\"))][['subjectid', 'visit']]\n",
    "print(Qdf.shape)\n",
    "print(\"Duplicated Q\")\n",
    "print(Qdf.loc[Qdf.duplicated()]) #should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####KSADS NOT READ FROM REDCAP ANYMORE...TOO BIG TO REIMPORT UNLESS CHANGES NEEDED. USE OLD VALUES\n",
    "#KSADSdf=getreport9(data=dataKSADS)\n",
    "\n",
    "#print(KSADSdf.columns)\n",
    "#print(KSADSdf.shape)\n",
    "#KSADSdf=KSADSdf.loc[~(KSADSdf.k_unusable=='1')][['patientid',  'patienttype']]\n",
    "#print(KSADSdf.shape)\n",
    "#KSADSdf.head()\n",
    "#KSADSdf=KSADSdf.loc[~(KSADSdf.patientid.str.upper().str.contains('CC'))]\n",
    "#print(KSADSdf.shape)\n",
    "#print(\"Duplicated KSADS\")\n",
    "#print(KSADSdf.loc[KSADSdf.duplicated()]) #should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdf.groupby('visit').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssagadf=getreport(data=dataSSAGA)\n",
    "#ssagadf=pd.read_csv(tempS)\n",
    "ssagadf.columns\n",
    "ssaga1=ssagadf.loc[ssagadf.redcap_event_name=='visit_1_arm_1'][['study_id','hcpa_id','register_visit_1_complete','v1_date','ssaga_complete']]\n",
    "print(ssaga1.shape)\n",
    "ssaga1=ssaga1.loc[~((ssaga1.v1_date=='') & (ssaga1.register_visit_1_complete=='0') & (ssaga1.ssaga_complete=='0'))]\n",
    "print(ssaga1.shape)\n",
    "ssaga1['event']='V1'\n",
    "subjectall=ssagadf.loc[ssagadf.redcap_event_name=='visit_1_arm_1'][['study_id','hcpa_id']]\n",
    "ssaga2=ssagadf.loc[ssagadf.redcap_event_name=='visit_2_arm_1'].drop(columns=['hcpa_id'])\n",
    "ssaga2=pd.merge(subjectall,ssaga2,on='study_id',how='right')\n",
    "ssaga2.head()\n",
    "ssaga2.loc[ssaga2.v2_date=='']\n",
    "print(ssaga2.shape)\n",
    "ssaga2=ssaga2.loc[~((ssaga2.v2_date=='') & (ssaga2.register_visit_2_complete=='0') & (ssaga2.ssaga_complete=='0'))]\n",
    "print(ssaga2.shape)\n",
    "ssaga2['event']='V2'\n",
    "\n",
    "\n",
    "ssaga=pd.concat([ssaga1,ssaga2],axis=0,sort=True)[['hcpa_id','event']]\n",
    "ssaga=ssaga.loc[~(ssaga.hcpa_id.str.upper().str.contains('CC'))]\n",
    "ssaga.groupby('event').count()\n",
    "#should be empty\n",
    "print(ssaga.loc[ssaga.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW PULL TOGETHER THE HCA INVENTORY \n",
    "   -from REDCAP HCPA (the main source of subject listings and data expectation determinations \n",
    "       after having dropped all the withdrawn, excluded, CC, or otherwise flagged records)\n",
    "   -from SSAGA (link by hcpa_id and event)\n",
    "   -from Penn (link by subid and assessment)\n",
    "   -from Toolbox (link by subject and event)\n",
    "   -from Q (link by subjectid and visit)\n",
    "#keep essential vars and flesh out expectations for other datatypes\n",
    "#merge in curated indicators.\n",
    "#already dropped the unusables, and the CCs from 2ndary sources.  Shouldnt be duplications per subject event but check counts as you go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDCAPs need extensive event, demographic, and visit summary harmonization\n",
    "#vars for all events\n",
    "#tempH='/home/petra/UbWinSharedSpace1/boxtemp/HCPA_DATA_2021-11-03_1551.csv'\n",
    "#HCAdf=pd.read_csv(tempH, low_memory=False)\n",
    "\n",
    "HCAdf=getreport(data=datahcpa)\n",
    "allevents=HCAdf.loc[HCAdf.redcap_event_name=='visit_1_arm_1'][['dob','id','psuedo_guid','subject_id','gender','site','racial','ethnic']].replace({'site':\n",
    "                                      {'1': 'MGH/Harvard', '2':'UCLA', '3':'UMinn', '4':'WashU'}})\n",
    "#races are not coded the same across databases\n",
    "allevents['race']=allevents.replace({'racial':\n",
    "                                       {'1':'American Indian/Alaska Native',\n",
    "                                        '2':'Asian',\n",
    "                                        '3':'Black or African American',\n",
    "                                        '4':'Hawaiian or Pacific Islander',\n",
    "                                        '5':'White',\n",
    "                                        '6':'More than one race',\n",
    "                                        '99':'Unknown or not reported'}})['racial']\n",
    "\n",
    "#ethnicities are not coded the same across databases\n",
    "allevents['ethnic_group']=allevents.replace({'ethnic':\n",
    "                                           {'1':'Hispanic or Latino',\n",
    "                                            '2':'Not Hispanic or Latino',\n",
    "                                            '3':'unknown or not reported'}})['ethnic']\n",
    "\n",
    "allevents['M/F']=allevents.replace({'gender':\n",
    "                                           {'1':'M',\n",
    "                                            '2':'F'}})['gender']\n",
    "\n",
    "\n",
    "#cpature the flags\n",
    "new = allevents['subject_id'].str.split(\"_\", 1, expand=True)\n",
    "allevents['subject'] = new[0].str.strip()\n",
    "allevents['flagged'] = new[1].str.strip()\n",
    "\n",
    "print(HCAdf.shape)\n",
    "#propagate all events fields throughout rest of events\n",
    "HCAdf1=pd.merge(allevents,HCAdf.drop(columns=['subject_id','dob','psuedo_guid','gender','site','racial','ethnic']),how='right',on='id')\n",
    "print(HCAdf1.shape)\n",
    "\n",
    "HCAdf1.loc[HCAdf1.flagged.isnull()==False][['subject_id','age']].sort_values('age').drop_duplicates(subset='subject_id',keep='last').to_csv('HCA_excluded.csv')\n",
    "\n",
    "#removed flagged individuals\n",
    "HCAdf1=HCAdf1.loc[HCAdf1.flagged.isnull()==True]\n",
    "print(HCAdf1.shape)  #the fact that there are two more from a right merge vs a left merge in the above merge \n",
    "#suggests to me that there are two subjects without v1 data...yay inventories.  who are they, though?    \n",
    "\n",
    "#recode event names\n",
    "HCAdf1['redcap_event']=HCAdf1.replace({'redcap_event_name':\n",
    "                                           {'visit_1_arm_1':'V1',\n",
    "                                            'follow_up_1_arm_1':'F1',\n",
    "                                            'visit_2_arm_1':'V2',\n",
    "                                             'follow_up_2_arm_1':'F2',\n",
    "                                            'covid_arm_1':'Covid',\n",
    "                                            'follow_up_3_arm_1':'F3',\n",
    "                                            'covid_remote_arm_1':'CR',\n",
    "                                            'actigraphy_arm_1':'A',\n",
    "                                           }})['redcap_event_name']\n",
    "\n",
    "HCAdf1[['site','redcap_event','id','psuedo_guid','subject','M/F','race','ethnic_group','v1_date','age','v2_date','age_v2','v3_date','age_v3',\n",
    "        'covid_dt', 'bt_covid_dt', 'rt_covid_dt']].head(5)\n",
    "#print(HCAdf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HCA Event Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(HCAdf1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map visits,ages, and event registrations.\n",
    "HCAdf1['sub_event']=HCAdf1['redcap_event']\n",
    "\n",
    "HCAdf1['sub_event_date']=''\n",
    "HCAdf1['sub_event_age']=''\n",
    "HCAdf1['sub_event_register']=''\n",
    "\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V1','event_date']=HCAdf1.v1_date\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V1','event_age']=HCAdf1.age\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V1','event_register']=HCAdf1.visit\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V1','sub_event']=\"1.V1\"\n",
    "\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F1','event_date']=HCAdf1.v3_date\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F1','event_age']=HCAdf1.age_v3\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F1','event_register']=HCAdf1.visit3\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F1','sub_event']=\"2.F1\"\n",
    "\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V2','event_date']=HCAdf1.v2_date\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V2','event_age']=HCAdf1.age_v2\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V2','event_register']=HCAdf1.visit2\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='V2','sub_event']=\"3.V2\"\n",
    "\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F2','event_date']=HCAdf1.v3_date #yes this is right.  FU events are longitudinally tracked\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F2','event_age']=HCAdf1.age_v3 #yes this is right.  FU events are longitudinally tracked\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F2','event_register']=HCAdf1.visit4 #yes this is right.  Event registers consider F2 to be visit4\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F2','sub_event']=\"4.F2\"\n",
    "\n",
    "\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F3','event_date']=HCAdf1.v3_date\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F3','event_age']=HCAdf1.age_v3\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F3','event_register']=HCAdf1.visit5\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='F3','sub_event']=\"5.F3\"\n",
    "            \n",
    "HCAdf1.loc[HCAdf1.redcap_event=='A','event_date']=HCAdf1.v6_startdate\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='A','event_age']=HCAdf1.age_v6\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='A','event_register']=HCAdf1.visit6\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='A','sub_event']=\"6.A\"\n",
    "\n",
    "#Covid\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='Covid','event_date']=HCAdf1.covid_dt\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='Covid','event_register']=HCAdf1.visit7\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='Covid','sub_event']='7.Covid1'\n",
    "\n",
    "#Covid2\n",
    "Covid2=HCAdf1.loc[HCAdf1.visit8.str.contains('8')].copy()\n",
    "Covid2.event_date=Covid2.bt_covid_dt\n",
    "Covid2.event_register=Covid2.visit8          \n",
    "Covid2.sub_event='8.Covid2'\n",
    "print(Covid2.shape)\n",
    "\n",
    "#Covid Remote\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='CR','event_date']=HCAdf1.rt_covid_dt\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='CR','event_register']=HCAdf1.visit9\n",
    "HCAdf1.loc[HCAdf1.redcap_event=='CR','sub_event']='9.Covid Remote'\n",
    "\n",
    "print(HCAdf1.shape)\n",
    "#add extra rows for covid2 event so that every event with a date has a row\n",
    "HCAdf2=pd.concat([HCAdf1,Covid2],axis=0)\n",
    "print(HCAdf2.shape)\n",
    "\n",
    "#populate ages where not calculated\n",
    "HCAdf2.loc[HCAdf2['event_date'].str.contains('2929'),'event_date']=''\n",
    "HCAdf2['alt_age']=(pd.to_datetime(HCAdf2['event_date'])-pd.to_datetime(HCAdf2['dob'])).dt.days/365.2425\n",
    "HCAdf2.reset_index(inplace=True)\n",
    "\n",
    "#assign missing ages to Covid Arms\n",
    "HCAdf2.loc[HCAdf2.redcap_event.isin(['Covid','CR']),'event_age']=HCAdf2.alt_age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#HCA Missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty rows (triggered by sending of survey to participant, where form status=0)\n",
    "#list(HCAdf2.columns)\n",
    "print(HCAdf2.shape)\n",
    "HCAdf3=HCAdf2.loc[~(HCAdf2.sub_event.isin(['7.Covid1']) & (HCAdf2.event_date.astype('str')=='') & (HCAdf2.covid_complete=='0'))]\n",
    "print(HCAdf3.shape)\n",
    "\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.sub_event.isin(['8.Covid2']) & (HCAdf3.event_date.astype('str')=='') & (HCAdf3.covid_2_complete=='0'))]\n",
    "print(HCAdf3.shape)\n",
    "\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.sub_event.isin(['9.Covid Remote']) & (HCAdf3.event_date.astype('str')=='') & (HCAdf3.covid_remote_complete=='0'))]\n",
    "print(HCAdf3.shape)\n",
    "\n",
    "#print(list(HCAdf3.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty rows for events that were triggered but have no registration\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.redcap_event.isin(['V1']) & (HCAdf3.event_register.astype('str')==''))]\n",
    "print(HCAdf3.shape)\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.redcap_event.isin(['F1']) & (HCAdf3.event_register.astype('str')==''))]\n",
    "print(HCAdf3.shape)\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.redcap_event.isin(['V2']) & (HCAdf3.event_register.astype('str')==''))]\n",
    "print(HCAdf3.shape)\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.redcap_event.isin(['F2']) & (HCAdf3.event_register.astype('str')==''))]\n",
    "print(HCAdf3.shape)\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.redcap_event.isin(['F3']) & (HCAdf3.event_register.astype('str')==''))]\n",
    "print(HCAdf3.shape)\n",
    "HCAdf3=HCAdf3.loc[~(HCAdf3.redcap_event.isin(['A']) & (HCAdf3.event_register.astype('str')==''))]\n",
    "print(HCAdf3.shape)\n",
    "\n",
    "\n",
    "HCAdf3=HCAdf3.sort_values(['site','sub_event','subject'])\n",
    "#HCAdf3[['site','redcap_event','sub_event','id','subject','event_date','M/F','event_age','race','ethnic_group','event_register',\n",
    "#        'v1_date','age','visit','v3_date','age_v3','visit3','visit4','visit5','v2_date','age_v2','visit2',\n",
    "#        'v6_startdate','age_v6','visit6','covid_dt','visit7','covid_complete','bt_covid_dt','visit8','covid_2_complete','rt_covid_dt','visit9', 'covid_remote_complete','alt_age']].to_csv('HCAlong.csv',index=False)\n",
    "#For table : RedCap AutoID\tHCA ID\tDate Registered\tM/F\tAge\n",
    "\n",
    "#now merge in visit summary info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep essential vars and flesh out expectations for other datatypes\n",
    "#merge in curated indicators.\n",
    "#already dropped the unusables, and the CCs.  Shouldnt be duplications per subject event\n",
    "print(pennHCA.columns)\n",
    "print(TLBXA.columns)\n",
    "##print(Qdf.columns)\n",
    "print(ssaga.columns)\n",
    "\n",
    "#pennHCA.head()\n",
    "#Qdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TLBX IDS that dont exist in REDCap: create trello card to investigate and possibly drop from curated\")\n",
    "tlbxwierdos=pd.merge(HCAdf3,TLBXA,how='right',left_on=['subject'],right_on=['subject'],indicator='TLBX_wierdos')\n",
    "print(tlbxwierdos.loc[tlbxwierdos.TLBX_wierdos=='right_only'][['subject']])\n",
    "#list(tlbxwierdos.subject.unique())\n",
    "\n",
    "\n",
    "print(\"Penn IDS that dont exist in REDCap: create trello card to investigate and set unusable in curated\")\n",
    "pennzos=pd.merge(HCAdf3,pennHCA,left_on=['subject'],right_on=['subid'],how='right',indicator=\"Pennzos\")\n",
    "print(pennzos.loc[pennzos.Pennzos=='right_only'][['subid']])\n",
    "\n",
    "##print(\"Ravlt IDs that doen't exist in REDCap: create trello cards to investigate and set unusable in curated\")\n",
    "##ravvos=pd.merge(HCAdf3,Qdf,left_on=['subject'],right_on=['subjectid'],how='right',indicator=\"Ravvos\")\n",
    "##print(ravvos.loc[(ravvos.Ravvos=='right_only') & ~(ravvos.subjectid.str.contains('HCD'))][['subjectid']])\n",
    "\n",
    "print(\"SSAGA IDs that don't exist in REDCap: create trello cards to investigate and drop from curated\")\n",
    "ssagos=pd.merge(HCAdf3,ssaga,left_on=['subject'],right_on=['hcpa_id'],how='right',indicator=\"Ssagos\")\n",
    "print(ssagos.loc[(ssagos.Ssagos=='right_only')][['hcpa_id']])\n",
    "\n",
    "#gold standard for withdrawn status is appendix to name in HCPA database.    \n",
    "#HCA7297488, HCA8680189, HCA8363682, HCA7361269 HCA9383491 HCA8415675--> all withdrawn or excluded . SSAGA database doesnt say as much but pre-release \n",
    "#folders already account for this information because they refer to the HCPA redcap database as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCA Curated_* Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Toolbox\n",
    "print(HCAdf3.shape)\n",
    "\n",
    "HCAdf4=pd.merge(HCAdf3,TLBXA,how='left',left_on=['subject','redcap_event'],right_on=['subject','event'],indicator='Curated_TLBX')\n",
    "HCAdf4.Curated_TLBX=HCAdf4.Curated_TLBX.str.replace('both','YES')\n",
    "HCAdf4.Curated_TLBX=HCAdf4.Curated_TLBX.str.replace('left_only','NO')\n",
    "HCAdf4.loc[~(HCAdf4.redcap_event.isin(['V1','V2','CR'])),'Curated_TLBX']='NE'\n",
    "\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='NO') & (HCAdf4.redcap_event.isin(['CR'])) & (HCAdf4.visit9.isin(['12'])),'Curated_TLBX']='SEE V2'\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='YES') & (HCAdf4.redcap_event.isin(['CR'])) & (HCAdf4.visit9.isin(['12'])),'Curated_TLBX']='YES BUT'\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='NO') & (HCAdf4.redcap_event.isin(['CR'])) & (HCAdf4.visit9.isin(['11'])),'Curated_TLBX']='SEE V1'\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='YES') & (HCAdf4.redcap_event.isin(['CR'])) & (HCAdf4.visit9.isin(['11'])),'Curated_TLBX']='YES BUT'\n",
    "\n",
    "\n",
    "HCAdf4['PIN']=HCAdf4.subject.str.cat(HCAdf4.redcap_event,sep=\"_\")\n",
    "#CR and visit exceptions to expections from trello\n",
    "trellolist=['HCA9681499_CR','HCA9447390_CR','HCA8628995_CR','HCA8034158_CR','HCA7985712_CR','HCA7954094_CR',\n",
    "            'HCA7689304_CR','HCA7670686_V2','HCA7513670_CR','HCA7184576_CR','HCA7024655_CR',\n",
    "            'HCA6766290_V2','HCA6766290_CR','HCA8867610_CR',\n",
    "            'HCA9198294_CR','HCA9944304_CR'] #'HCA7423063_CR','HCA6250255_CR','HCA6691992_CR','HCA6400450_CR', removed from this list since all V2 data types collected same day\n",
    "#trelloseev1\n",
    "#trelloseev2\n",
    "#trelloseecr\n",
    "\n",
    "\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='NO') & HCAdf4.PIN.isin(trellolist),'Curated_TLBX']='NE TRELLO'\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='YES') & HCAdf4.PIN.isin(trellolist),'Curated_TLBX']='YES BUT'\n",
    "\n",
    "#general notes catches\n",
    "redlist=['HCA9796921_V2','HCA9735294_V2','HCA8595300 V1','HCA9734999_V2','HCA8163169_V1','HCA7424873_V1',\n",
    "         'HCA7474181_V2','HCA7296183_V2','HCA9461182_V2','HCA8689410_V1','HCA8249078_V2','HCA8829905_V2',\n",
    "         'HCA7474181_V1','HCA9093684_V2','HCA9383491_V1','HCA9914193_V3','HCA8595300_V1']\n",
    "\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='NO') & (HCAdf4.PIN.isin(redlist)),'Curated_TLBX']='NE PM'\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='YES') & (HCAdf4.PIN.isin(redlist)),'Curated_TLBX']='YES BUT'\n",
    "\n",
    "\n",
    "\n",
    "double=['HCA7581081_V2','HCA8530978_V1']\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='NO') & (HCAdf4.PIN.isin(double)),'Curated_TLBX']='SEE DOUBLE'\n",
    "HCAdf4.loc[(HCAdf4.Curated_TLBX=='YES') & (HCAdf4.PIN.isin(double)),'Curated_TLBX']='YES BUT'\n",
    "\n",
    "\n",
    "\n",
    "HCAdf4=HCAdf4.drop(columns=['event'])\n",
    "#HCAdf4.to_csv('HCAexp4.csv',index=False)\n",
    "print(HCAdf4.shape)\n",
    "\n",
    "#get double winner ids\n",
    "HCAdf4=pd.merge(HCAdf4,doubles,left_on='subject',right_on='HCAid',how='left')           \n",
    "HCAdf4.head()\n",
    "print(HCAdf4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get pennHCA, \n",
    "HCAdf5=pd.merge(HCAdf4,pennHCA,left_on=['subject','redcap_event'],right_on=['subid','assessment'],how='left',indicator=\"Curated_PennCNP\")\n",
    "HCAdf5.Curated_PennCNP=HCAdf5.Curated_PennCNP.str.replace('both','YES')\n",
    "HCAdf5.Curated_PennCNP=HCAdf5.Curated_PennCNP.str.replace('left_only','NO')\n",
    "HCAdf5.loc[~(HCAdf5.redcap_event.isin(['V1','V2','CR'])),'Curated_PennCNP']='NE'\n",
    "\n",
    "#HCAdf5.loc[(HCAdf4.Curated_PennCNP=='NO') & (HCAdf5.redcap_event.isin(['CR'])) & (HCAdf5.visit9.isin(['12','11'])),'Curated_PennCNP']='NE'\n",
    "#HCAdf5.loc[(HCAdf5.redcap_event.isin(['CR'])) & (HCAdf5.visit9.isin(['12','11'])),'Curated_PennCNP']='NE'\n",
    "\n",
    "HCAdf5.loc[(HCAdf5.Curated_PennCNP=='NO') & (HCAdf5.redcap_event.isin(['CR'])) & (HCAdf5.visit9.isin(['12'])),'Curated_PennCNP']='SEE V2'\n",
    "HCAdf5.loc[(HCAdf5.Curated_PennCNP=='YES') & (HCAdf5.redcap_event.isin(['CR'])) & (HCAdf5.visit9.isin(['12'])),'Curated_PennCNP']='YES BUT'\n",
    "HCAdf5.loc[(HCAdf5.Curated_PennCNP=='NO') & (HCAdf5.redcap_event.isin(['CR'])) & (HCAdf5.visit9.isin(['11'])),'Curated_PennCNP']='SEE V1'\n",
    "HCAdf5.loc[(HCAdf5.Curated_PennCNP=='YES') & (HCAdf5.redcap_event.isin(['CR'])) & (HCAdf5.visit9.isin(['11'])),'Curated_PennCNP']='YES BUT'\n",
    "\n",
    "\n",
    "\n",
    "HCAdf5=HCAdf5.drop(columns=['subid','assessment'])\n",
    "print(HCAdf5.shape)\n",
    "print('### HI')\n",
    "#get Q\n",
    "Qdf['event']=Qdf.visit.astype('str')\n",
    "Qdf.event=Qdf.event.str.replace('1','V1')\n",
    "Qdf.event=Qdf.event.str.replace('2','V2')\n",
    "Qdf2=Qdf.drop(columns=['visit'])\n",
    "\n",
    "HCAdf6=HCAdf5.copy()\n",
    "HCAdf6=pd.merge(HCAdf5,Qdf2,left_on=['subject','redcap_event'],right_on=['subjectid', 'event'],how='left',indicator=\"Curated_Q\")\n",
    "HCAdf6.Curated_Q=HCAdf6.Curated_Q.str.replace('both','YES')\n",
    "HCAdf6.Curated_Q=HCAdf6.Curated_Q.str.replace('left_only','NO')\n",
    "HCAdf6.loc[~(HCAdf6.redcap_event.isin(['V1','V2','CR'])),'Curated_Q']='NE'\n",
    "HCAdf6=HCAdf6.drop(columns=['subjectid', 'event'])\n",
    "\n",
    "\n",
    "HCAdf6.loc[(HCAdf6.Curated_Q=='NO') & (HCAdf6.redcap_event.isin(['CR'])) & (HCAdf6.visit9.isin(['12'])),'Curated_Q']='SEE V2'\n",
    "HCAdf6.loc[(HCAdf6.Curated_Q=='YES') & (HCAdf6.redcap_event.isin(['CR'])) & (HCAdf6.visit9.isin(['12'])),'Curated_Q']='YES BUT'\n",
    "HCAdf6.loc[(HCAdf6.Curated_Q=='NO') & (HCAdf6.redcap_event.isin(['CR'])) & (HCAdf6.visit9.isin(['11'])),'Curated_Q']='SEE V1'\n",
    "HCAdf6.loc[(HCAdf6.Curated_Q=='YES') & (HCAdf6.redcap_event.isin(['CR'])) & (HCAdf6.visit9.isin(['11'])),'Curated_Q']='YES BUT'\n",
    "\n",
    "print(HCAdf6.shape)\n",
    "\n",
    "#and SSAGA\n",
    "HCAdf7=pd.merge(HCAdf6,ssaga,left_on=['subject','redcap_event'],right_on=['hcpa_id', 'event'],how='left',indicator=\"Curated_SSAGA\")\n",
    "HCAdf7.Curated_SSAGA=HCAdf7.Curated_SSAGA.str.replace('both','YES')\n",
    "HCAdf7.Curated_SSAGA=HCAdf7.Curated_SSAGA.str.replace('left_only','NO')\n",
    "HCAdf7.loc[~(HCAdf7.redcap_event.isin(['V1','V2'])),'Curated_SSAGA']='NE'\n",
    "\n",
    "HCAdf7=HCAdf7.drop(columns=['hcpa_id', 'event'])\n",
    "print(HCAdf7.shape)\n",
    "\n",
    "#misscat for visit summary v1 and v2:  1, Scan | 2, REDCap | 3, Toolbox | 7, UPennCNP | 4, RAVLT | 6, Trail-making | 8, SSAGA   \n",
    "HCAdf7.loc[(HCAdf7.misscat___7=='1') & (HCAdf7.Curated_PennCNP=='NO'),'Curated_PennCNP']='NE PM'\n",
    "HCAdf7.loc[(HCAdf7.misscat___4=='1') & (HCAdf7.Curated_Q=='NO'),'Curated_Q']='NE PM'\n",
    "HCAdf7.loc[(HCAdf7.misscat___8=='1') & (HCAdf7.Curated_SSAGA=='NO'),'Curated_SSAGA']='NE PM'\n",
    "HCAdf7.loc[(HCAdf7.misscat___7=='1') & (HCAdf7.Curated_PennCNP=='YES'),'Curated_PennCNP']='YES BUT'\n",
    "HCAdf7.loc[(HCAdf7.misscat___4=='1') & (HCAdf7.Curated_Q=='YES'),'Curated_Q']='YES BUT'\n",
    "HCAdf7.loc[(HCAdf7.misscat___8=='1') & (HCAdf7.Curated_SSAGA=='YES'),'Curated_SSAGA']='YES BUT'\n",
    "\n",
    "\n",
    "#HCA6937998_CR, HCA8508480_CR are UMN subjects with 'had V2 data collection' checked, so no CR expected- make sure logic excludes them (UMN)\n",
    "\n",
    "#OTHER CR subjects with all signs of PENN_CNP data explicitly NOT expected\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.covid_remote_complete=='2') & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_pt___3=='0') & (HCAdf7.covid_summary_rt_pt___4=='0')) & (HCAdf7.covid_summary_rt_test=='1'),'Curated_PennCNP']='NE PM'#[['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_summary_rt_pt___3','covid_summary_rt_pt___4','covid_summary_rt_pt___5','covid_summary_rt_test','covid_summary_notes']] \n",
    "\n",
    "#CR subjects with all signs of RAVLT data NOT expected\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.covid_remote_complete=='2') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='0') & (HCAdf7.covid_summary_rt_test=='1'),'Curated_Q']='NE PM'\n",
    "\n",
    "\n",
    "#1, Covid Surveys | 2, MoCA | 3, Delayed Discounting | 4, Emotion Recognition | 5, RAVLT | 6, Picture Sequence Memory | 7, Picture Vocabulary | 8, List Sorting | 9, Oral Reading\n",
    "#CR subjects with all signs of RAVLT expected at V1\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.event_register=='9')  & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='1') & (HCAdf7.covid_summary_rt_test=='2'),'Curated_Q']='SEE V1'\n",
    "#CR subjects with all signs of RAVLT expected at V2\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='1') & (HCAdf7.covid_summary_rt_test=='3'),'Curated_Q']='SEE V2'\n",
    "\n",
    "#CR subjects with all signs of PENNCNP expected at V1\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.event_register=='9')  & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_pt___3=='1') | (HCAdf7.covid_summary_rt_pt___4=='1')) & (HCAdf7.covid_summary_rt_test=='2'),'Curated_PennCNP']='SEE V1'\n",
    "#CR subjects with all signs of PENNCNP expected at V2\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_pt___3=='1') | (HCAdf7.covid_summary_rt_pt___4=='1')) & (HCAdf7.covid_summary_rt_test=='3'),'Curated_PennCNP']='SEE V2'\n",
    "\n",
    "#CR subjects with all signs of TLBX expected at V1\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_TLBX=='NO') & (HCAdf7.event_register=='9')  & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_pt___6=='1') | (HCAdf7.covid_summary_rt_pt___7=='1') | (HCAdf7.covid_summary_rt_pt___8=='1') | (HCAdf7.covid_summary_rt_pt___9=='1')) & (HCAdf7.covid_summary_rt_test=='2'),'Curated_TLBX']='SEE V1'\n",
    "#CR subjects with all signs of TLBX expected at V2\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_TLBX=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_pt___6=='1') | (HCAdf7.covid_summary_rt_pt___7=='1') | (HCAdf7.covid_summary_rt_pt___8=='1') | (HCAdf7.covid_summary_rt_pt___9=='1')) & (HCAdf7.covid_summary_rt_test=='3'),'Curated_TLBX']='SEE V2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssaga.loc[ssaga.hcpa_id==\"HCA7297488\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###special clauses for MGH and UCLA, who didn't complete visit summaries in same way as rest of sites:\n",
    "\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject=='HCA8379495'), \"Curated_PennCNP\"]=\"NE PM\"\n",
    "\n",
    "mgpin=['HCA6476584','HCA6686191']\n",
    "for i in mgpin:\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject==i), \"Curated_SSAGA\"]=\"NE PM\"\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject==i), \"Curated_PennCNP\"]=\"NE PM\"\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject==i), \"Curated_Q\"]=\"NE PM\"\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject==i), \"Curated_TLBX\"]=\"NE PM\"\n",
    "\n",
    "\n",
    "mgpin2=['HCA9071068','HCA9190884']\n",
    "for i in mgpin2:\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject==i), \"Curated_SSAGA\"]=\"SEE V1\"\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject==i), \"Curated_PennCNP\"]=\"SEE V1\"\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject==i), \"Curated_Q\"]=\"SEE V1\"\n",
    "    HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject==i), \"Curated_TLBX\"]=\"SEE V1\"\n",
    "\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA8502872'), \"Curated_SSAGA\"]=\"SEE V2\"\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA8502872'), \"Curated_PennCNP\"]=\"SEE V2\"\n",
    "##HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA8502872'), \"Curated_Q\"]=\"SEE V2\"\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA8502872'), \"Curated_TLBX\"]=\"SEE V2\"\n",
    "\n",
    "#special WashU cases:\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject=='HCA7133155'), \"Curated_Q\"]=\"SEE CR\"\n",
    "\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject=='HCA7372476'), \"Curated_PennCNP\"]='SEE CR'\n",
    "\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject=='HCA7987312'),'Curated_PennCNP']='SEE CR' \n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject=='HCA7987312'),'Curated_Q']='SEE CR' \n",
    "\n",
    "\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA6766290'), \"Curated_Q\"]=\"NE PM\"\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA6766290'), \"Curated_Q\"]=\"NE PM\"\n",
    "\n",
    " \n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA9187693'), \"Curated_PennCNP\"]=\"NE PM\"\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA9187693'), \"Curated_Q\"]=\"NE PM\"\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject=='HCA9187693'), \"Curated_TLBX\"]=\"NE PM\"\n",
    "\n",
    "    \n",
    "#CR subject with all signs of TLBX data NOT expected\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_TLBX=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_test=='1') & (HCAdf7.covid_summary_rt_pt___6=='0') & (HCAdf7.covid_summary_rt_pt___7=='0')  & (HCAdf7.covid_summary_rt_pt___8=='0')  & (HCAdf7.covid_summary_rt_pt___9=='0'),'Curated_TLBX']=\"NE PM\"\n",
    "           #[['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "\n",
    "\n",
    "#CR subject with all signs of Q data NOT expected\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_test=='1') | (HCAdf7.covid_summary_rt_test=='2') | (HCAdf7.covid_summary_rt_test=='3')) & (HCAdf7.covid_summary_rt_pt___5=='0'),'Curated_Q']=\"NE PM\"#[['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "##HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_test=='1') & (HCAdf7.covid_summary_rt_pt___5=='0'),'Curated_Q']=\"NE PM\"#[['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "\n",
    "#CR subject with all signs of PennCNP data NOT expected\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_test=='1') | (HCAdf7.covid_summary_rt_test=='2') | (HCAdf7.covid_summary_rt_test=='3')) & (HCAdf7.covid_summary_rt_pt___3=='0') & (HCAdf7.covid_summary_rt_pt___4=='0'),'Curated_PennCNP']=\"NE PM\"#,'Curated_Q']#=\"NE PM\"#[['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_test=='1') & (HCAdf7.covid_summary_rt_pt___3=='0') & (HCAdf7.covid_summary_rt_pt___4=='0'),'Curated_PennCNP']=\"NE PM\"#,'Curated_Q']#=\"NE PM\"#[['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "\n",
    "HCAdf7=HCAdf7.loc[~(HCAdf7.subject.str.upper().str.contains('TEST'))]\n",
    "HCAdf7=HCAdf7.loc[~(HCAdf7.subject.str.upper().str.contains('TRAINING'))]\n",
    "print(HCAdf7.shape)\n",
    "list(HCAdf7.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAdf7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CR subjects with all signs of RAVLT expected at V1\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.event_register=='9')  & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='1') & (HCAdf7.covid_summary_rt_test=='2'),'Curated_Q']#='SEE V1'\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='YES') & (HCAdf7.event_register==9)  & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='1') & (HCAdf7.covid_summary_rt_test=='2'),'Curated_Q']='YES BUT'\n",
    "##CR subjects with all signs of RAVLT expected at V2\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='1') & (HCAdf7.covid_summary_rt_test=='3'),'Curated_Q']#='SEE V2'\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='YES') & (HCAdf7.event_register==9)  & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='1') & (HCAdf7.covid_summary_rt_test=='3'),'Curated_Q']='YES BUT'\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.event_register=='9')  & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_pt___3=='1') | (HCAdf7.covid_summary_rt_pt___4=='1')) & (HCAdf7.covid_summary_rt_test=='2'),'Curated_PennCNP']\n",
    "#CR subject with all signs of Q data NOT expected\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.event_register=='9') & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_test=='1') | (HCAdf7.covid_summary_rt_test=='2') | (HCAdf7.covid_summary_rt_test=='3')) & (HCAdf7.covid_summary_rt_pt___3=='0') & (HCAdf7.covid_summary_rt_pt___4=='0')]#,'Curated_Q']#=\"NE PM\"#[['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "print(HCAdf7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missingness for CR, in lieu of being able to trust NOs at this point, since so many visit summaries missing:    \n",
    "#1, Separate Remote Battery | 2, V1 Data Collection | 3, V2 Data Collection\n",
    "#covid_summary_rt_pt:1, Covid Surveys | 2, MoCA | 3, Delayed Discounting | 4, Emotion Recognition | 5, RAVLT | 6, Picture Sequence Memory | 7, Picture Vocabulary | 8, List Sorting | 9, Oral Reading\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "\n",
    "##subjects who likely just need to have their visit summaries updated or filled out if not the above\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO')][['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___3','covid_summary_rt_pt___4','covid_summary_rt_pt___5','covid_summary_rt_test','covid_summary_notes','event_date']]#.to_csv('testCRsummary.csv')\n",
    "\n",
    "#special wacky case where subject accidentally had CR and V2 back to back.\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='V2') & (HCAdf7.subject_id=='HCA7133155'),'Curated_Q']='SEE CR'\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject_id=='HCA7133155'),'Curated_TLBX']='SEE V2'\n",
    "HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.subject_id=='HCA7133155'),'Curated_PennCNP']='SEE_V2'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjects with all signs of data expected (but for whom data has not been located)\n",
    "a=HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_PennCNP=='NO') & (HCAdf7.covid_remote_complete=='2') & (HCAdf7.covid_remote_summary_complete=='2') & ((HCAdf7.covid_summary_rt_pt___3=='1') | (HCAdf7.covid_summary_rt_pt___4=='1')) & (HCAdf7.covid_summary_rt_test=='1')][['site','subject_id','redcap_event','event_date','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___3','covid_summary_rt_pt___4','covid_summary_rt_pt___5','covid_summary_rt_test','covid_summary_notes']] \n",
    "#missingness for CR (Q)\n",
    "print(a)\n",
    "\n",
    "#subjects with all signs of data expected (but for whom data has not been located)\n",
    "##b=HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO') & (HCAdf7.covid_remote_complete=='2') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_pt___5=='1') & (HCAdf7.covid_summary_rt_test=='1')][['site','subject_id','redcap_event','event_date','covid_summary_notes']]#.to_csv('missingCR_Ravlt.csv',index=False) \n",
    "##print(b)\n",
    "\n",
    "#'covid_summary_rt_pt___3','covid_summary_rt_pt___4','covid_summary_rt_pt___5','covid_remote_summary_complete','event_register','covid_remote_complete','covid_summary_rt_test',\n",
    "#subjects who likely just need to have their visit summaries updated or filled out if not the above\n",
    "##c=HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_Q=='NO')][['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___5','covid_summary_rt_pt___5','covid_summary_rt_test','covid_summary_notes','event_date']]#.to_csv('testCRsummary.csv')\n",
    "##print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missingness for CR (TLBX)\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_TLBX=='NO') & (HCAdf7.covid_remote_complete=='2') & (HCAdf7.covid_remote_summary_complete=='2') & ~(HCAdf7.covid_summary_rt_test=='1')][['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "\n",
    "#HCAdf7.loc[(HCAdf7.redcap_event=='CR') & (HCAdf7.Curated_TLBX=='NO') & (HCAdf7.covid_remote_complete=='2') & (HCAdf7.covid_remote_summary_complete=='2') & (HCAdf7.covid_summary_rt_test=='1') & (test.covid_summary_rt_pt___6=='0') & (test.covid_summary_rt_pt___7=='0')  & (test.covid_summary_rt_pt___8=='0')  & (test.covid_summary_rt_pt___9=='0')][['site','subject_id','redcap_event','event_register','covid_remote_complete','covid_remote_summary_complete','covid_summary_rt_pt___6','covid_summary_rt_pt___7','covid_summary_rt_pt___8','covid_summary_rt_pt___9','covid_summary_rt_test','covid_summary_notes','event_date']]\n",
    "#test.loc[(test.covid_summary_rt_pt___6=='0') & (test.covid_summary_rt_pt___7=='0')  & (test.covid_summary_rt_pt___8=='0')  & (test.covid_summary_rt_pt___9=='0')]\n",
    "\n",
    "#remove duplicates. \n",
    "print(\"BEFORE DE-DUP\")\n",
    "print(HCAdf7.shape)\n",
    "\n",
    "print(HCAdf7.loc[HCAdf7.duplicated()]) #should be empty\n",
    "\n",
    "HCAdf7.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "\n",
    "print(\"After DE-DUP\")\n",
    "print(HCAdf7.shape)\n",
    "\n",
    "\n",
    "HCAdf7.loc[~(HCAdf7.redcap_event.isin(['V1','V2','CR'])),'PIN']=''\n",
    "\n",
    "HCAdf7.loc[HCAdf7.site=='MGH/Harvard','site']='MGH'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#last minute 'yes but' fixes that were a result of visit summary form shortcomings (as opposed to data that should be \n",
    "#examined more closely)\n",
    "HCAdf7.loc[(HCAdf7.PIN=='HCA7987312_CR'),'Curated_Q']='YES'\n",
    "HCAdf7.loc[(HCAdf7.PIN=='HCA7987312_CR'),'Curated_PennCNP']='YES'\n",
    "HCAdf7.loc[(HCAdf7.PIN=='HCA9968823_V1'),'Curated_PennCNP']='NE PM'\n",
    "Qlist=['HCA6605569_V1','HCA7106657_V1','HCA7723782_V1','HCA8829905_V1']\n",
    "HCAdf7.loc[HCAdf7.PIN.isin(Qlist),'Curated_Q']='YES'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NDA VARS\n",
    "#nda interview date\n",
    "HCAdf7['nda_interview_date']=pd.to_datetime(HCAdf7['event_date']) - pd.offsets.QuarterBegin(startingMonth=1)\n",
    "\n",
    "#nda age in months\n",
    "HCAdf7['nda_age'] = (\n",
    "        12 * (pd.to_datetime(HCAdf7['event_date']).dt.year - pd.to_datetime(HCAdf7.dob).dt.year) +\n",
    "        (pd.to_datetime(HCAdf7['event_date']).dt.month - pd.to_datetime(HCAdf7.dob).dt.month) +\n",
    "        (pd.to_datetime(HCAdf7['event_date']).dt.day - pd.to_datetime(HCAdf7.dob).dt.day) / 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAdf7['nda_age']=HCAdf7.nda_age.apply(np.floor).round()\n",
    "#HCAdf7.nda_age=HCAdf7.nda_age.round() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCAdf7['check_age']= HCAdf7.event_age.replace('',np.nan).astype(float)*12\n",
    "#NO LONGER ROUNDING AGE FOR NDA\n",
    "#HCAdf7.loc[HCAdf7.nda_age > 1080, 'nda_age'] = 1200\n",
    "\n",
    "HCAdf7.sort_values(by='nda_age',ascending=False)[['subject','redcap_event','event_age','nda_age','event_date','nda_interview_date']]\n",
    "#merge in pedfinal by pseudo_guid\n",
    "\n",
    "pedfinal.head()\n",
    "HCAdf7=pd.merge(pedfinal,HCAdf7,how='right',on='psuedo_guid')#,indicator='bb')\n",
    "#HCAdf7.bb.value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAdf7.loc[HCAdf7.nda_age.isnull()==True][['redcap_event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an Imaging Flag double check for sessions that don't exist in inventory\n",
    "intradb=pd.read_csv('/home/petra/Behavioral/Lifespan/PreRelease/PreRelease/CCF_HCA_STG_20230217.csv')\n",
    "intradb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradb['subject']=intradb.Subject\n",
    "intradb['redcap_event']= intradb['MR ID'].str.split('_', expand=True)[1]\n",
    "intradb['IntraDB']='CCF_HCA_STG'\n",
    "#intradb.visit\n",
    "#intradb[['subject','visit']]\n",
    "listScanner=['HCA9814189','HCA8343272','HCA7126865','HCA8715687','HCA9137577','HCA6780789','HCA8858104',\n",
    "             'HCA6732980','HCA8540678','HCA8043765','HCA8738598','HCA6426670','HCA6878504','HCA7411864',\n",
    "             'HCA8935904','HCA7025859','HCA9808700']\n",
    "HCAdf7=pd.merge(HCAdf7,intradb[['subject','redcap_event','IntraDB']],on=['subject','redcap_event'], how='outer',indicator=True)\n",
    "\n",
    "HCAdf7.loc[((HCAdf7.redcap_event=='V1') & (HCAdf7.subject.isin(listScanner))),'IntraDB']='CCF_PCMP_ITK'\n",
    "HCAdf7._merge.value_counts()\n",
    "HCAdf7.loc[HCAdf7._merge=='right_only'][['subject','redcap_event']]\n",
    "#not releaseing HCA7297488\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAdf7._merge.value_counts()\n",
    "HCAdf7=HCAdf7.loc[HCAdf7._merge !='right_only'].copy()\n",
    "HCAdf7=HCAdf7.drop(columns=['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP HCA9461182 V2\n",
    "HCAdf7=HCAdf7.loc[~((HCAdf7.subject=='HCA9461182') & (HCAdf7.redcap_event=='V2'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAdf7.loc[((HCAdf7.redcap_event=='V2') & (HCAdf7.IntraDB.isnull()==True)),'IntraDB']='Behavioral Only'\n",
    "\n",
    "\n",
    "HCAdf7.IntraDB.value_counts()\n",
    "#HCAdfb.subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAdf7.loc[(HCAdf7.IntraDB=='') & (HCAdf7.redcap_event=='V2')]\n",
    "#HCAdf7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#create days since first date\n",
    "HCAdf7.event_date=pd.to_datetime(HCAdf7.event_date)\n",
    "\n",
    "date1=HCAdf7.sort_values(['subject','event_date'])[['subject','event_date']].drop_duplicates(subset=['subject'],keep='first').rename(columns={'event_date':'first_date'})\n",
    "print(date1[['subject','first_date']].head())\n",
    "HCAdf8=pd.merge(HCAdf7,date1,how='left',on='subject')\n",
    "\n",
    "HCAdf8['daysfromtime0']=(HCAdf8.event_date - HCAdf8.first_date).dt.days\n",
    "#HCAdf8['daysfromtime0'].days()\n",
    "print(HCAdf8.daysfromtime0.head())\n",
    "HCAdf8['DB_Source']='hcpa'\n",
    "\n",
    "#export inventory\n",
    "#For both partial and complete COVID Remote responses, cognitive testing is (check one):\n",
    "#1, Separate Remote Battery | 2, V1 Data Collection | 3, V2 Data Collection\n",
    "#covid_summary_rt_pt:1, Covid Surveys | 2, MoCA | 3, Delayed Discounting | 4, Emotion Recognition | 5, RAVLT | 6, Picture Sequence Memory | 7, Picture Vocabulary | 8, List Sorting | 9, Oral Reading\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "covidcols=[ #'sub_event',\n",
    "# 'sub_event_date',\n",
    "# 'sub_event_age',\n",
    "# 'sub_event_register',\n",
    "# 'covid_remote_complete',\n",
    "# 'moca_complete',\n",
    "# 'covid_protocol_order',\n",
    "# 'covid_summary1',\n",
    "# 'covid_summary2',\n",
    " 'covid_summary_rt',\n",
    " 'covid_summary_rt_pt___1',\n",
    " 'covid_summary_rt_pt___2',\n",
    " 'covid_summary_rt_pt___3',\n",
    " 'covid_summary_rt_pt___4',\n",
    " 'covid_summary_rt_pt___5',\n",
    " 'covid_summary_rt_pt___6',\n",
    " 'covid_summary_rt_pt___7',\n",
    " 'covid_summary_rt_pt___8',\n",
    " 'covid_summary_rt_pt___9',\n",
    " 'covid_summary_rt_test',\n",
    " 'covid_remote_summary_complete',          \n",
    " 'covid_summary_notes']\n",
    "\n",
    "#ALL columns, unmasked\n",
    "allcols=['pedid','nda_age', 'nda_interview_date','dob','psuedo_guid', 'DB_Source','HCAid','HCDid','site','redcap_event_name','sub_event','redcap_event',\n",
    "          'event_register','event_date','daysfromtime0','id','subject','race','ethnic_group','M/F','height','weight',\n",
    "        'event_age','Curated_SSAGA','Curated_PennCNP', 'Curated_Q','Curated_TLBX','IntraDB',\n",
    "        'DateFinished','PIN', 'general_note', 'misscat___3','misscat___7','misscat___4','misscat___8','misstoolbox',\n",
    "        'missupenncnp', 'misstravlt','missssaga']+covidcols #'dob','mstrl2_last','fp_mstrl2_last',\n",
    "\n",
    "HCAdf8[allcols].rename(columns={'id':'REDCap_id','psuedo_guid':'pseudo_guid'}).to_csv('HCA_AllSources_'+snapshotdate+'.csv',index=False)\n",
    "\n",
    "\n",
    "#slim is for the pre-release folder (has no dates)\n",
    "slimcols=['pedid','nda_age',  'nda_interview_date','psuedo_guid', 'DB_Source','HCAid','HCDid','site','sub_event','redcap_event','redcap_event_name',\n",
    "          'daysfromtime0','id','subject','race','ethnic_group','M/F','height','weight',\n",
    "        'event_age','IntraDB','Curated_SSAGA','Curated_PennCNP', 'Curated_Q','Curated_TLBX',\n",
    "        'PIN']\n",
    "\n",
    "\n",
    "#mask ages above 90\n",
    "HCAdf8.event_age=pd.to_numeric(HCAdf8.event_age)#.astype(float,errors='ignore')\n",
    "HCAdf8.loc[HCAdf8.event_age>90,'event_age']=90.0\n",
    "HCAdf8.sub_event_age=pd.to_numeric(HCAdf8.sub_event_age)#.astype(float,errors='ignore')\n",
    "HCAdf8.loc[HCAdf8.sub_event_age>90,'sub_event_age']=90.0\n",
    "\n",
    "HCAdf8[slimcols].rename(columns={'psuedo_guid':'pseudo_guid','id':'REDCap_id'}).to_csv('HCA_AllSourcesSlim_'+snapshotdate+'.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAdf8.IntraDB.value_counts()\n",
    "print(HCAdf8.loc[HCAdf8.redcap_event.isin(['V1','V2','V3'])].redcap_event.value_counts()) #HCAdf8.IntraDB=='CCF_HCA_STG']\n",
    "print(HCAdf8.loc[(HCAdf8.redcap_event.isin(['V1','V2','V3'])) & (HCAdf8.IntraDB=='CCF_HCA_STG')].redcap_event.value_counts()) #HCAdf8.IntraDB=='CCF_HCA_STG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.V1\n",
    "#2.F1\n",
    "#3.V2\n",
    "#4.F2\n",
    "#5.F3\n",
    "#6.A\n",
    "#7.Covid1\n",
    "#8.Covid2\n",
    "#9.Covid Remote\n",
    "#misscat for visit summary v1 and v2:  1, Scan | 2, REDCap | 3, Toolbox | 7, UPennCNP | 4, RAVLT | 6, Trail-making | 8, SSAGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW FOR THE HCD Inventory - just focus on child/parent combos first...then HCD18 after\n",
    "NOW PULL TOGETHER THE HCA INVENTORY \n",
    "   -from REDCAP HCPD child (the main source of subject listings and data expectation determinations \n",
    "       after having dropped all the withdrawn, excluded, CC, or otherwise flagged records)\n",
    "   -from REDCap parent (link by child_id and redcap_event)\n",
    "   -from KSADS (subset by patientid into subject and event...two to 4 possible columns w/patienttype and Mood possibilities)\n",
    "   -from Penn (link by subid and assessment)\n",
    "   -from Toolbox (link by subject and event)\n",
    "   -from Q (link by subjectid and visit)\n",
    "   -from eprime\n",
    "#keep essential vars and flesh out expectations for other datatypes\n",
    "#merge in curated indicators.\n",
    "#already dropped the unusables, and the CCs.  Shouldnt be duplications per subject event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#####HCD ########################################################\n",
    "# Two subs ids were changed by removing their _CC appendage in redcap.  This will change any downstream tallies of missingness.\n",
    "# and lead to discrepancies with respect to old lists of exclusions.  \n",
    "# The alternative would be to fix all places in the code where these two subjects need to be exceptions to a CC rule.\n",
    "# Seeing as lists of exclusions weren't formalized until 2022, it probably makes cleaner sense to change REDCap.\n",
    "# Plastering IDs here, just in case : HCD0123824_V1 (parent HCD3110325) and HCD2059043_V1 (parent HCD3621855)\n",
    "# Neither had siblings or other visits, so clean up in REDCap was relatively simple.  Just removed the _CC.\n",
    "\n",
    "\n",
    "HCDchilddf=getreport(data=datachild)\n",
    "HCDparentdf=getreport(data=dataparents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#HCDparentdf.loc[HCDparentdf.parent_id=='HCD4256459']\n",
    "HCDchilddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars for all events (race and ethnicity from parents) \n",
    "#note that parent_id is at V1...different parents came in for different visits\n",
    "dfnewparent=HCDparentdf.loc[HCDparentdf.redcap_event_name=='visit_1_arm_1'][['id','child_id','parent_id','p_c_race___10','p_c_race___11','p_c_race___12','p_c_race___14','p_c_race___18','p_c_race___25','p_c_race___99','p_c_latino']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCPDchildrens parents can select multiple race options (checkbox)...need to convert those to 'more than one race' category of mutually exclusive\n",
    "#version of race variable required by NDAR\n",
    "#12, NATIVE AMERICAN | 18, ASIAN |  11, BLACK/AFRICAN AMERICAN |  14, NATIVE HAWAIIAN or\n",
    "#OTHER PACIFIC ISLANDER |10, WHITE | 25, MORE THAN ONE RACE |  99, DON'T KNOW\n",
    "\n",
    "dfnewparent.p_c_race___10=dfnewparent.p_c_race___10.str.strip().replace('','0').astype(int)\n",
    "dfnewparent.p_c_race___11=dfnewparent.p_c_race___11.str.strip().replace('','0').astype(int)\n",
    "dfnewparent.p_c_race___12=dfnewparent.p_c_race___12.str.strip().replace('','0').astype(int)\n",
    "dfnewparent.p_c_race___14=dfnewparent.p_c_race___14.str.strip().replace('','0').astype(int)\n",
    "dfnewparent.p_c_race___18=dfnewparent.p_c_race___18.str.strip().replace('','0').astype(int)\n",
    "dfnewparent.p_c_race___25=dfnewparent.p_c_race___25.str.strip().replace('','0').astype(int)\n",
    "dfnewparent.p_c_race___99=dfnewparent.p_c_race___99.str.strip().replace('','0').astype(int)\n",
    "\n",
    "dfnewparent['sumcheckedrace']=dfnewparent[['p_c_race___10','p_c_race___11','p_c_race___12','p_c_race___14','p_c_race___18','p_c_race___25']].sum(axis=1)\n",
    "\n",
    "dfnewparent.loc[(dfnewparent.sumcheckedrace==1) & (dfnewparent.p_c_race___10==1),'racial']=5\n",
    "dfnewparent.loc[(dfnewparent.sumcheckedrace==1) & (dfnewparent.p_c_race___11==1),'racial']=3\n",
    "dfnewparent.loc[(dfnewparent.sumcheckedrace==1) & (dfnewparent.p_c_race___12==1),'racial']=1\n",
    "dfnewparent.loc[(dfnewparent.sumcheckedrace==1) & (dfnewparent.p_c_race___14==1),'racial']=4\n",
    "dfnewparent.loc[(dfnewparent.sumcheckedrace==1) & (dfnewparent.p_c_race___18==1),'racial']=2\n",
    "dfnewparent.loc[(dfnewparent.sumcheckedrace==1) & (dfnewparent.p_c_race___25==1),'racial']=6\n",
    "dfnewparent.loc[(dfnewparent.sumcheckedrace==0) & (dfnewparent.p_c_race___99==1),'racial']=99\n",
    "\n",
    "dfnewparent.loc[dfnewparent.sumcheckedrace>=2,'racial']=6\n",
    "\n",
    "dfnewparent['race']=dfnewparent.replace({'racial':\n",
    "                                       {1:'American Indian/Alaska Native',\n",
    "                                        2:'Asian',\n",
    "                                        3:'Black or African American',\n",
    "                                        4:'Hawaiian or Pacific Islander',\n",
    "                                        5:'White',\n",
    "                                        6:'More than one race',\n",
    "                                        99:'Unknown or not reported'}})['racial']\n",
    "\n",
    "dfnewparent['ethnic_group']=dfnewparent.replace({'p_c_latino':\n",
    "                                           {'1':'Hispanic or Latino',\n",
    "                                            '0':'Not Hispanic or Latino',\n",
    "                                            '9':'unknown or not reported'}})['p_c_latino']\n",
    "\n",
    "\n",
    "dfnewparent['redcap_id_parent']=dfnewparent['id']\n",
    "\n",
    "dfnewparent[['p_c_race___10','p_c_race___11','p_c_race___12','p_c_race___14','p_c_race___18','p_c_race___25','p_c_race___99','sumcheckedrace','race']]\n",
    "\n",
    "#capture the flags - note that flags in parents might not be same as flags in kids.  Gold standard for flags is child db\n",
    "new = dfnewparent['child_id'].str.split(\"_\", 1, expand=True)\n",
    "dfnewparent['subject'] = new[0].str.strip()\n",
    "dfnewparent['flaggedparent'] = new[1].str.strip()\n",
    "\n",
    "dfnewparent=dfnewparent.drop(columns='id')\n",
    "dfnewparent.columns\n",
    "print(dfnewparent.shape)\n",
    "dfnewparent=dfnewparent.loc[~((dfnewparent.parent_id==\"\") & (dfnewparent.child_id==\"\"))]\n",
    "print(dfnewparent.shape)\n",
    "dfnewparentslim=dfnewparent.loc[dfnewparent.flaggedparent.isnull()==True]\n",
    "print(dfnewparentslim.shape)\n",
    "print(\"this number should match first argument of previous print statement, indicating no duplicates:\")\n",
    "print(len(dfnewparentslim.child_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the duplicate.  remove if just an empty record\n",
    "dfnewparentslim.loc[dfnewparentslim.duplicated(subset='child_id')]\n",
    "dfnewparentslim.loc[dfnewparentslim.child_id=='']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCDchilddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab vars for all events from child db\n",
    "dfchild=HCDchilddf.loc[HCDchilddf.redcap_event_name=='visit_1_arm_1'][['age','dob','id','subject_id','gender','site','psuedo_guid']].replace({'site':{'1': 'MGH/Harvard', '2':'UCLA', '3':'UMinn', '4':'WashU'}})\n",
    "print(dfchild.shape)\n",
    "\n",
    "dfchild['M/F']=dfchild.replace({'gender': {'1':'M', '2':'F'}})['gender']\n",
    "#dfchild=dfchild.rename(columns={'id':'redcap_id_child'})\n",
    "\n",
    "\n",
    "new = dfchild['subject_id'].str.split(\"_\", 1, expand=True)\n",
    "dfchild['subject'] = new[0].str.strip()\n",
    "dfchild['flagged'] = new[1].str.strip()\n",
    "print(dfchild.shape)\n",
    "\n",
    "idsflagged=dfchild.loc[dfchild.flagged.isnull()==False][['id']] #grab the id not the subject so you can drop the whole row\n",
    "dfchild.loc[dfchild.flagged.isnull()==False][['subject_id','age']].sort_values('age').drop_duplicates(subset='subject_id',keep='last').to_csv('childexclusions.csv',index=False)\n",
    "\n",
    "dfchildslim=dfchild.loc[dfchild.flagged.isnull()==True]\n",
    "print(dfchildslim.shape)\n",
    "print(\"this number should match first argument of previous print statement, indicating no duplicates:\")\n",
    "print(len(dfchildslim.subject.unique()))\n",
    "\n",
    "duplicates = dfchildslim[(dfchildslim.duplicated(subset='subject') == True)].sort_values('subject')\n",
    "dups=list(duplicates.subject)\n",
    "dfchildslim.loc[dfchildslim.subject.isin(dups)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precursor to parent id cleanup issues\n",
    "list(idsflagged.id)\n",
    "diffs=pd.merge(dfchildslim[['subject','subject_id']],dfnewparentslim[['subject','child_id']],on='subject',how='outer',indicator=True)\n",
    "diffs.loc[~(diffs._merge=='both')]\n",
    "#these all appear to be subjects for whom data collection has not begun in earnest\n",
    "#if they still exist at the end of data collection, please delete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge races from parents with child record\n",
    "#child db is gold standard for subject list\n",
    "allevents=pd.merge(dfchildslim,dfnewparentslim,how='left',on='subject')\n",
    "\n",
    "extraparents=pd.merge(dfchildslim,dfnewparentslim,how='outer',on='subject',indicator=True)\n",
    "extraparents.loc[extraparents._merge==\"right_only\"]#these are all bogus typo ids with no data\n",
    "print(allevents.shape)\n",
    "allevents[['subject','subject_id','child_id','parent_id']].loc[allevents.parent_id.isnull()==True]#,'flagged','flaggedparent']].head()\n",
    "\n",
    "allevents=allevents.loc[~(allevents.subject==\"TEST\")]\n",
    "print(allevents.shape)\n",
    "#allevents.loc[allevents.id.isin(list(idsflagged.id))]\n",
    "allevents.loc[(allevents.subject_id.isnull()==True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the parent_id to parent_at_V1 to make it obvious that this can change\n",
    "allevents=allevents[['dob', 'id', 'subject_id','psuedo_guid', 'gender', 'site', 'M/F', 'subject',\n",
    "       'flagged', 'child_id', 'parent_id', 'race',\n",
    "       'ethnic_group', 'redcap_id_parent', 'flaggedparent']].rename(columns={'parent_id':'parent_at_V1'})\n",
    "allevents.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#propagate all events fields throughout rest of events (child) and then check that flagged entities are excluded (should be case since merging by id)\n",
    "print(HCDchilddf.shape)\n",
    "#need to keep the right merge in case there are subjects for whom no v1 data.  \n",
    "HCDchilddf2=pd.merge(allevents,HCDchilddf.drop(columns=['subject_id','dob','gender','site','psuedo_guid']),how='right',on='id')\n",
    "print(HCDchilddf2.shape)\n",
    "\n",
    "HCDchilddf3=HCDchilddf2.loc[~(HCDchilddf2.id.isin(list(idsflagged.id)))].copy()\n",
    "print(HCDchilddf3.shape)\n",
    "\n",
    "HCDchilddf3=HCDchilddf3.loc[~(HCDchilddf3.subject_id.isnull()==True)]#[['id','suject','redcap_event_name']]\n",
    "#HCDchilddf3.columns\n",
    "print(HCDchilddf3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCDchilddf3.columns\n",
    "#HCDchilddf3.redcap_event_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode event names for linking with other data sources\n",
    "#map parent and child events to same variables\n",
    "HCDchilddf3['redcap_event']=HCDchilddf3.replace({'redcap_event_name':\n",
    "                                           {'visit_1_arm_1':'V1',\n",
    "                                            'follow_up_arm_1':'F1',\n",
    "                                            'visit_2_arm_1':'V2',\n",
    "                                            'visit_3_arm_1':'V3',\n",
    "                                            'covid_2_arm_1':'Covid2'\n",
    "                                           }})['redcap_event_name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCD Child Event Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCDchilddf3['event_date']=''\n",
    "HCDchilddf3['event_age']=''\n",
    "HCDchilddf3['event_register']=''\n",
    "\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event.isin(['V1','F1','V2','V3']),'event_date']=HCDchilddf3.intake_date\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event.isin(['V1','F1','V2','V3']),'event_age']=HCDchilddf3.age\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event.isin(['Covid2']),'event_age']=HCDchilddf3.covidy_age\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event.isin(['Covid2']),'event_date']=HCDchilddf3.covidy_dt\n",
    "\n",
    "#there appears to have been some inconsistent effort at linking event names across REDCap data sources...\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event=='V1','event_register']=HCDchilddf3.visit\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event=='F1','event_register']=HCDchilddf3.visit4\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event=='V2','event_register']=HCDchilddf3.visit2\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event=='V3','event_register']=HCDchilddf3.visit3\n",
    "HCDchilddf3.loc[HCDchilddf3.redcap_event=='Covid2','event_register']=HCDchilddf3.visit8\n",
    "print(HCDchilddf3.shape)\n",
    "#HCDchilddf3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty rows\n",
    "print(HCDchilddf3.shape)\n",
    "HCDchilddf4=HCDchilddf3.loc[~(HCDchilddf3.redcap_event.isin(['F1']) & (HCDchilddf3.event_register.astype('str')==''))]\n",
    "print(HCDchilddf4.shape)\n",
    "#HCDchilddf4.loc[(HCDchilddf4.event_register=='4')& (HCDchilddf4.event_date=='')]\n",
    "#print(HCDchilddf4.shape)\n",
    "HCDchilddf4=HCDchilddf4.loc[~(HCDchilddf4.redcap_event.isin(['V1']) & (HCDchilddf4.event_register.astype('str')==''))]\n",
    "print(HCDchilddf4.shape)\n",
    "HCDchilddf4=HCDchilddf4.loc[~(HCDchilddf4.redcap_event.isin(['V2']) & (HCDchilddf4.event_register.astype('str')==''))]\n",
    "print(HCDchilddf4.shape)\n",
    "HCDchilddf4=HCDchilddf4.loc[~(HCDchilddf4.redcap_event.isin(['V3']) & (HCDchilddf4.event_register.astype('str')==''))]\n",
    "print(HCDchilddf4.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove more empty rows\n",
    "print(HCDchilddf4.shape)\n",
    "#HCDchilddf5=HCDchilddf4.copy()\n",
    "HCDchilddf5=HCDchilddf4.loc[~(HCDchilddf4.redcap_event.isin(['Covid2']) & (HCDchilddf4.event_date=='') & (HCDchilddf4.covid_19_questionnaire_youth_complete=='0'))]\n",
    "print(HCDchilddf5.shape)\n",
    "#print(HCDchilddf3.shape)\n",
    "HCDchilddf5.to_csv('test.csv',index=False)\n",
    "#misscat: 1, Scan | 2, REDCap | 3, Toolbox | 9, Cognitive Testing | 5, KSADS\n",
    "#HCDchilddf5[['id','subject_id','gender','site','M/F','subject','flagged','child_id','parent_at_V1','race','ethnic_group','redcap_id_parent','flaggedparent','redcap_event_name','redcap_event','event_date','event_age','event_register','visit','visit2','visit3','visit4','visit8','visit_type','intake_date','age','covidy_dt','covidy_age','covid_19_questionnaire_youth_complete']].sort_values(['site','redcap_event']).to_csv('hcdtest.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCDchilddf5.loc[HCDchilddf5.subject_id.str.contains('HCD0813243')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find second parent IDs (e.g. when a different parent came in for v2 or something)\n",
    "###PPPPPPPPPP###\n",
    "HCDparentdf['redcap_event']=HCDparentdf.replace({'redcap_event_name':\n",
    "                                           {'visit_1_arm_1':'V1',\n",
    "                                            'follow_up_arm_1':'F1',\n",
    "                                            'visit_2_arm_1':'V2',\n",
    "                                            'visit_3_arm_1':'V3',\n",
    "                                            'covid_arm_1': 'Covid',\n",
    "                                            'covid_2_arm_1':'Covid2'\n",
    "                                           }})['redcap_event_name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCDparentdf.groupby('redcap_event').count()\n",
    "HCDparentdf.loc[HCDparentdf.redcap_event.isnull()==True]\n",
    "HCDparentdf.columns\n",
    "#HCDchilddf5.loc[HCDchilddf5['redcap_id_parent'].str.strip()=='14']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allevents.shape)\n",
    "allevents.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some EVENTS (covid related) in the parent database that not in the \n",
    "#child database...moreover some EVENTS in child but not in parents (children who turned 18 during study)\n",
    "#List of eligible SUBJECTS are the same (or should be after end of study) within both databases, but need\n",
    "#to be careful when making a pooled inventory, that you don't end up with blocks of missing information outside the intersection\n",
    "\n",
    "#want all events from both dbs without reintroducing withdrawns.  \n",
    "\n",
    "#make sure not to set to empty where events in child but not parent\n",
    "\n",
    "\n",
    "initvars=['id','parent_id','child_id']#,'site','p_c_race___10','p_c_race___11','p_c_race___12','p_c_race___14','p_c_race___18','p_c_race___25','p_c_race___99','p_c_latino','p_c_sex','dob']\n",
    "parentinit=HCDparentdf.loc[HCDparentdf.parent_id.str.contains('HCD')][initvars].rename(columns={'parent_id':'parent_at_V1'})\n",
    "parentinit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with v1 parent initiated for parent_at_visit column, and then overwrite\n",
    "parentinit['parent_at_visit']=parentinit['parent_at_V1']\n",
    "print(HCDparentdf.shape)\n",
    "#HCDparentdf2=pd.merge(parentinit,HCDparentdf.drop(columns=['child_id','site','p_c_sex','dob']),on='id',how='left')\n",
    "HCDparentdf2=pd.merge(parentinit,HCDparentdf.drop(columns=['child_id']),on='id',how='left')\n",
    "print(HCDparentdf2.shape)\n",
    "\n",
    "#subset to records corresponding to children that arent excluded or anything (per redcap id of parent in previous parent and child merge by subject_id and child_id)\n",
    "#note that we cant use child redcap ids to drop withdrawns in this case because arm in child db doesnt exist for some parent data\n",
    "listchilluns=list(HCDchilddf5.loc[HCDchilddf5['redcap_id_parent'].isnull()==False,'redcap_id_parent'].unique())\n",
    "listchilluns\n",
    "print(HCDparentdf2.shape)\n",
    "HCDparentdf2=HCDparentdf2.loc[HCDparentdf2['id'].isin(listchilluns)]\n",
    "print(HCDparentdf2.shape)\n",
    "\n",
    "HCDparentdf2.loc[~(HCDparentdf2.parent_id_dif==''),'parent_at_visit']=HCDparentdf2.parent_id_dif\n",
    "#HCDparentdf2[['site','id','parent_at_visit','parent_id','parent_id_dif','child_id','redcap_event_name']]#=HCDparentdf.parent_id_dif\n",
    "print(HCDparentdf2.columns)\n",
    "HCDparentdf2[['id', 'parent_at_V1', 'parent_at_visit','child_id']].head()\n",
    "#print(len(listchilluns))\n",
    "\n",
    "\n",
    "#NOte that this won't solve all the ID problems because parent at visit isn't necessarily parent at SESSION \n",
    "#(e.g. the id on the TOOLBOX data).  These had to be hard coded in from info available in notes sections \n",
    "# of visit summaries.  This happens later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(listchilluns))\n",
    "print('child shape using different methods of making sure withdrawns were excluded:' + str(dfchildslim.shape))\n",
    "child=pd.DataFrame(HCDchilddf5.subject.unique(),columns=['subject'])\n",
    "#parent=pd.DataFrame(HCDparentdf2.child_id.unique(),columns=['subject'])\n",
    "parent=pd.DataFrame(HCDparentdf2.id.unique(),columns=['id'])\n",
    "child.head()\n",
    "parent.head()\n",
    "print(\"child shape: \" + str(child.shape))\n",
    "print(\"parent shape: \" + str(parent.shape))\n",
    "print(\"if the large numbers above all agree, that means we have successfully subset the parent and child databases to subject that should be in both (and are not withdrawn or otherwise excluded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCD Parent Event Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCDparentdf2.head()\n",
    "HCDparentdf2.columns\n",
    "HCDparentdf2['event_date']=''\n",
    "#HCDparentdf2['event_age']=''\n",
    "HCDparentdf2['event_register']=''\n",
    "\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event.isin(['V1','F1','V2','V3']),'event_date']=HCDparentdf2.intake_date\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event.isin(['Covid']),'event_date']=HCDparentdf2.covid_dt\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event.isin(['Covid2']),'event_date']=HCDparentdf2.covidy_dt\n",
    "\n",
    "\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event=='V1','event_register']=HCDparentdf2.visit\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event=='F1','event_register']=HCDparentdf2.visit4\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event=='V2','event_register']=HCDparentdf2.visit2\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event=='V3','event_register']=HCDparentdf2.visit3\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event=='Covid','event_register']=HCDparentdf2.visit7\n",
    "HCDparentdf2.loc[HCDparentdf2.redcap_event=='Covid2','event_register']=HCDparentdf2.visit8\n",
    "\n",
    "#remove empty rows:\n",
    "print(HCDparentdf2.shape)\n",
    "HCDparentdf2=HCDparentdf2.loc[~(HCDparentdf2.redcap_event.isin(['Covid2']) & (HCDparentdf2.event_date=='') & (HCDparentdf2.covid_19_questionnaire_parent_complete=='0'))]\n",
    "print(HCDparentdf2.shape)\n",
    "HCDparentdf2=HCDparentdf2.loc[~(HCDparentdf2.redcap_event.isin(['Covid']) & (HCDparentdf2.event_date=='') & (HCDparentdf2.covid_complete=='0'))]\n",
    "print(HCDparentdf2.shape)\n",
    "HCDparentdf2=HCDparentdf2.loc[~(HCDparentdf2.redcap_event.isin(['F1','V2','V3']) & (HCDparentdf2.event_register=='') )]\n",
    "\n",
    "\n",
    "print(HCDparentdf2.shape)\n",
    "HCDparentdf2.columns\n",
    "#HCDparentdf2[['id', 'site', 'redcap_event_name','redcap_event', 'event_date', 'event_register' ,'child_id',\n",
    "#              'parent_id','parent_at_visit', 'visit8', 'visit_type', 'intake_date', 'parent_id_yn',\n",
    "#       'parent_id_dif', 'covid_dt', 'covidy_dt', 'covid_complete', 'covid_19_questionnaire_parent_complete']].to_csv('hcdparenttest.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCDchilddf5.head()\n",
    "HCDchilddf5.shape\n",
    "HCDchilddf5.to_csv('test.csv',index=False)\n",
    "alllist=['dob',\n",
    " 'id',\n",
    " 'subject_id',\n",
    " 'psuedo_guid',\n",
    " 'gender',\n",
    " 'site',\n",
    " 'M/F',\n",
    " 'subject',\n",
    " 'flagged',\n",
    " 'parent_at_V1',\n",
    " 'race',\n",
    " 'ethnic_group',\n",
    " 'redcap_id_parent',\n",
    " 'flaggedparent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCD parent and child Curated_* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that all vars in common are mapped, get parents and children into a single inventory\n",
    "#fill in holes where stuff outside the intersection of subject and event merge resides.  \n",
    "#rename a few things so its obvious whose data we're discussing\n",
    "\n",
    "#Where missing: 'covid_arm_1': 'Covid',\n",
    "    \n",
    "#parents=HCDparentdf2[['parent_at_visit','parent_at_V1','site','gender','child_id','redcap_event','event_date','id','p_c_sex','race','ethnic_group','dob']].rename(columns={'event_date':'p_event_date','id':'redcap_id_parent','dob':'p_c_dob'})\n",
    "#parents=parents.replace({'site':{'1': 'MGH/Harvard', '2':'UCLA', '3':'UMinn', '4':'WashU'}})\n",
    "parents=HCDparentdf2[['parent_at_visit','child_id','redcap_event','event_date','event_register']].rename(columns={'event_date':'p_event_date','event_register':'p_event_register'})\n",
    "childs=HCDchilddf5.copy()\n",
    "#misscat: 1, Scan | 2, REDCap | 3, Toolbox | 9, Cognitive Testing | 5, KSADS\n",
    "#misstoolbox: 1, Child | 2, Parent about Child | 3, Parent about Parent\n",
    "\n",
    "parents.head()\n",
    "childs.columns #head()\n",
    "\n",
    "#findchild\n",
    "#togetherinventory=pd.merge(parents,childs.drop(columns=['child_id','parent_at_V1','redcap_id_parent','site','race','ethnic_group']),how='outer',left_on=['child_id','redcap_event'],right_on=['subject','redcap_event'], indicator=True)\n",
    "togetherinventory=pd.merge(parents,childs.drop(columns=['child_id']),how='outer',left_on=['child_id','redcap_event'],right_on=['subject','redcap_event'], indicator=True)\n",
    "togetherinventory._merge=togetherinventory._merge.str.replace('left_only','parent_only')\n",
    "togetherinventory._merge=togetherinventory._merge.str.replace('both','parentandchild')\n",
    "\n",
    "togetherinventory._merge=togetherinventory._merge.str.replace('right_only','child_only')\n",
    "togetherinventory=togetherinventory.rename(columns={'_merge':'DB_Source'})\n",
    "togetherinventory.reset_index(inplace=True)\n",
    "\n",
    "#theseones have now lost their 'child_id'] because event was in child only\n",
    "togetherinventory.loc[togetherinventory.child_id.isnull()==True,'child_id']=togetherinventory.subject\n",
    "\n",
    "\n",
    "#pull in the allevents vars again for the ones in parent only\n",
    "togetherinventory2=pd.merge(togetherinventory.drop(columns=alllist),allevents,on='child_id',how='left')\n",
    "togetherinventory2.loc[togetherinventory2.event_date.isnull()==True,'event_date']=togetherinventory2.p_event_date\n",
    "togetherinventory2.loc[togetherinventory2.event_register.isnull()==True,'event_register']=togetherinventory2.p_event_register\n",
    "togetherinventory2.loc[togetherinventory2.event_age.isnull()==True,'event_age']=(pd.to_datetime(togetherinventory2['event_date'])-pd.to_datetime(togetherinventory2['dob'])).dt.days/365.2425\n",
    "togetherinventory2.loc[(togetherinventory2.redcap_event_name.isnull()==True) & (togetherinventory2.redcap_event=='Covid'),'redcap_event_name']='covid_arm_1'\n",
    "\n",
    "\n",
    "\n",
    "togetherinventory2.to_csv('test2.csv',index=False)\n",
    "\n",
    "#create basic event expectations for Toolbox\n",
    "##toolbox\n",
    "togetherinventory2=pd.merge(togetherinventory2.drop(columns=['subject']),TLBXD,how='left',left_on=['child_id','redcap_event'],right_on=['subject','event'],indicator=True)\n",
    "togetherinventory2=togetherinventory2.rename(columns={'_merge':'Curated_TLBX_ChildPIN'}).drop(columns=['event','subject'])\n",
    "togetherinventory2.Curated_TLBX_ChildPIN=togetherinventory2.Curated_TLBX_ChildPIN.str.replace('both','YES')\n",
    "togetherinventory2.Curated_TLBX_ChildPIN=togetherinventory2.Curated_TLBX_ChildPIN.str.replace('left_only','NO')\n",
    "togetherinventory2.loc[(togetherinventory2.Curated_TLBX_ChildPIN=='NO') & (togetherinventory2.redcap_event.isin(['F1','Covid1','Covid2'])),'Curated_TLBX_ChildPIN']=\"NE\"\n",
    "#togetherinventory2.columns\n",
    "\n",
    "togetherinventory3=pd.merge(togetherinventory2.rename(columns={'DateFinished':'ChildDateFinishedTLBX'}),TLBXD.rename(columns={'DateFinished':'ParentDateFinishedTLBX'}),how='left',left_on=['parent_at_visit','redcap_event'],right_on=['subject','event'],indicator=True)\n",
    "togetherinventory3=togetherinventory3.rename(columns={'_merge':'Curated_TLBX_ParentPIN'}).drop(columns=['event','subject'])\n",
    "togetherinventory3.Curated_TLBX_ParentPIN=togetherinventory3.Curated_TLBX_ParentPIN.str.replace('both','YES')\n",
    "togetherinventory3.Curated_TLBX_ParentPIN=togetherinventory3.Curated_TLBX_ParentPIN.str.replace('left_only','NO')\n",
    "togetherinventory3.loc[(togetherinventory3.Curated_TLBX_ParentPIN=='NO') & (togetherinventory3.redcap_event.isin(['F1','Covid1','Covid2'])),'Curated_TLBX_ParentPIN']=\"NE\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch missing redcap_event_name variables in parentonly situations\n",
    "togetherinventory3.loc[(togetherinventory3.redcap_event_name.isnull()==True) & (togetherinventory3.redcap_event=='F1'),'redcap_event_name']='follow_up_arm_1'\n",
    "togetherinventory3.loc[(togetherinventory3.redcap_event_name.isnull()==True) & (togetherinventory3.redcap_event=='Covid2'),'redcap_event_name']='covid_2_arm_1'\n",
    "togetherinventory3.loc[(togetherinventory3.redcap_event_name.isnull()==True) & (togetherinventory3.redcap_event=='Covid1'),'redcap_event_name']='covid_arm_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "childs.head()\n",
    "list(allevents.columns)\n",
    "allevents.loc[allevents.flagged.isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pennHCD.columns)\n",
    "print(erows.columns)\n",
    "print(TLBXD.columns)\n",
    "print(Qdf.columns)\n",
    "#no more loading KSADS from REDCAP...archived#\n",
    "#print(KSADSdf.columns)\n",
    "print(doubles.columns)\n",
    "\n",
    "Qdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "togetherinventory3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now pull in Penn, Eprime Qinteractive,KSADS,for children\n",
    "togetherinventory3.columns\n",
    "colms=['redcap_id_parent','id','parent_at_visit','parent_at_V1','child_id','site','event_age','redcap_event','DB_Source','event_date','p_event_date','M/F','p_c_sex','race','ethnic_group','ChildDateFinishedTLBX','ChildPINfound','ParentDateFinishedTLBX','ParentPINfound','visit','visit2','visit3','visit4','visit8','visit_type','intake_date','age','covidy_dt','covidy_age','register_visit_complete','register_covid2_complete','register_follow_up_complete','register_visit3_complete','register_visit2_complete','register_visit1_complete','intake_interview_complete','puberty_complete','subject_data_block_1_complete','subject_data_block_2_complete','participant_satisfaction_survey_complete','achenbach_alert_complete','external_measures_complete','follow_up_complete','covid_19_questionnaire_youth_complete','toolbox_complete','remote_toolbox_emotion_complete','misstoolbox___1','misstoolbox___2','misstoolbox___3','misscat___1','misscat___2','misscat___3','misscat___9','misscat___5','data_status','misstoolboxc','misstoolboxpc','misstoolboxpp','general_note']\n",
    "togetherinventory4=pd.merge(togetherinventory3,pennHCD,left_on=['child_id','redcap_event'],right_on=['subid','assessment'],how='left',indicator=True) #the ones in Penn but not together are the 18+ yos\n",
    "togetherinventory4=togetherinventory4.rename(columns={'_merge':'Curated_PennCNP'})\n",
    "togetherinventory4.Curated_PennCNP=togetherinventory4.Curated_PennCNP.str.replace('both','YES')\n",
    "togetherinventory4.Curated_PennCNP=togetherinventory4.Curated_PennCNP.str.replace('left_only','NO')\n",
    "togetherinventory4['agetest']=pd.to_numeric(togetherinventory4['event_age'],errors='coerce')\n",
    "togetherinventory4.loc[(togetherinventory4.Curated_PennCNP==\"NO\") & (togetherinventory4.agetest<8),'Curated_PennCNP']='NE AGE'\n",
    "togetherinventory4.loc[togetherinventory4.redcap_event.isin(['F1','Covid2','Covid1']),'Curated_PennCNP']='NE'\n",
    "togetherinventory4.loc[(togetherinventory4.Curated_PennCNP=='NO') & (togetherinventory4.misscat___9=='1') & (togetherinventory4.misscog___2=='1'),'Curated_PennCNP']='NE PM'\n",
    "togetherinventory4.loc[(togetherinventory4.Curated_PennCNP=='YES') & (togetherinventory4.misscat___9=='1') & (togetherinventory4.misscog___2=='1'),'Curated_PennCNP']='YES BUT'\n",
    "#togetherinventory4.loc[togetherinventory4.event_age.astype(float)<8.0,'Curated_PennCNP']='NE'\n",
    "\n",
    "# drop PENN ids known to be permanently missing\n",
    "#perm_misslist = [\n",
    "#    'HCA6012744',\n",
    "#    'HCA6605569',\n",
    "#    'HCA8689410',\n",
    "#    'HCA8735289',\n",
    "#    'HCA8917700',\n",
    "#    'HCA9695713',\n",
    "#    'HCD1539759',\n",
    "#    'HCD1714852',\n",
    "#    'HCD1769978',\n",
    "#    'HCD2642858',\n",
    "#    'HCD2913459',\n",
    "#    'HCD2978386']\n",
    "#togetherinventory4.loc[(togetherinventory4.Curated_PennCNP==\"NO\") & (togetherinventory4.child_id.isin(perm_misslist)),'Curated_PennCNP']='NE'\n",
    "\n",
    "togetherinventory4=togetherinventory4.drop(columns=['subid','assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "togetherinventory4.groupby('redcap_event').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eprime\n",
    "#misscat: 1, Scan | 2, REDCap | 3, Toolbox | 9, Cognitive Testing | 5, KSADS\n",
    "#misstoolbox: 1, Child | 2, Parent about Child | 3, Parent about Parent\n",
    "#misscog: 1, Q-Interactive - matrix reasoning | 2, UPennCNP | 3, Delayed Discounting\n",
    "\n",
    "\n",
    "\n",
    "togetherinventory5=pd.merge(togetherinventory4,erows.rename(columns={'visit':'evisit'}),left_on=['child_id','redcap_event'],right_on=['subject','evisit'],how='left',indicator=True) #the ones in Penn but not together are the 18+ yos\n",
    "togetherinventory5=togetherinventory5.rename(columns={'_merge':'Curated_Eprime'})\n",
    "togetherinventory5.Curated_Eprime=togetherinventory5.Curated_Eprime.str.replace('both','YES')\n",
    "togetherinventory5.Curated_Eprime=togetherinventory5.Curated_Eprime.str.replace('left_only','NO')\n",
    "togetherinventory5.loc[(togetherinventory5.Curated_Eprime==\"NO\") & (togetherinventory5.agetest>8),'Curated_Eprime']=\"NE AGE\"\n",
    "togetherinventory5.loc[(togetherinventory5.redcap_event.isin(['Covid1','Covid2','F1','V2','V3'])),'Curated_Eprime']='NE'\n",
    "togetherinventory5.loc[(togetherinventory5.Curated_Eprime=='NO') & (togetherinventory5.misscat___9=='1') & (togetherinventory4.misscog___3=='1'),'Curated_Eprime']='NE PM'\n",
    "togetherinventory5.loc[(togetherinventory5.Curated_Eprime=='YES') & (togetherinventory5.misscat___9=='1') & (togetherinventory4.misscog___3=='1'),'Curated_Eprime']='YES BUT'\n",
    "\n",
    "togetherinventory5=togetherinventory5.drop(columns=['subject','evisit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Qdf.columns)\n",
    "Qdf.groupby('visit').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Q\n",
    "Qdf['event']=Qdf.visit.astype('str')\n",
    "Qdf.event=Qdf.event.str.replace('1','V1')\n",
    "Qdf.event=Qdf.event.str.replace('2','V2')\n",
    "Qdf.event=Qdf.event.str.replace('3','V3')\n",
    "Qdf2=Qdf.drop(columns=['visit'])\n",
    "#misscog: 1, Q-Interactive - matrix reasoning | 2, UPennCNP | 3, Delayed Discounting\n",
    "\n",
    "togetherinventory6=pd.merge(togetherinventory5,Qdf2,left_on=['child_id','redcap_event'],right_on=['subjectid', 'event'],how='left',indicator=\"Curated_Q\")\n",
    "togetherinventory6.Curated_Q=togetherinventory6.Curated_Q.str.replace('both','YES')\n",
    "togetherinventory6.Curated_Q=togetherinventory6.Curated_Q.str.replace('left_only','NO')\n",
    "togetherinventory6.loc[~(togetherinventory6.redcap_event.isin(['V1','V2','V3'])),'Curated_Q']='NE'\n",
    "togetherinventory6.loc[(togetherinventory6.Curated_Q=='NO') & (togetherinventory6.misscat___9=='1') & (togetherinventory4.misscog___1=='1'),'Curated_Q']='NE PM'\n",
    "togetherinventory6.loc[(togetherinventory6.Curated_Q=='YES') & (togetherinventory6.misscat___9=='1') & (togetherinventory4.misscog___1=='1'),'Curated_Q']='YES BUT'\n",
    "\n",
    "\n",
    "togetherinventory6=togetherinventory6.drop(columns=['subjectid', 'event'])\n",
    "\n",
    "#togetherinventory6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##NO MORE GETTING KSADS FROM REDCAP - USED VARIABLES FROM PREVIOUS VERSION OF INVENTORY\n",
    "#KSADSdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(togetherinventory6.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENTED OUT BECAUSE KSADS NO LONGER IN REDCAP...KEEP DATA FROM PREVIOUS VERSION OF INVENTORY\n",
    "\n",
    "#There are four types of KSADS data corresponding to four IDs that need to be merged into inventory\n",
    "#parent, child, parent MOOD and child MOOD. Sometimes (no indication as to when) \n",
    "#Mood and regular info was collected under same battery (e.g. a regular old V1 id).   \n",
    "\n",
    "#print(KSADSdf.columns)\n",
    "#KSADSdf.patientid.head()\n",
    "#new = KSADSdf['patientid'].str.split(\"_\", 1, expand=True)\n",
    "#KSADSdf['subject'] = new[0].str.strip()\n",
    "#KSADSdf['event'] = new[1].str.strip()\n",
    "#KSADSdf['event']=KSADSdf['event'].str.upper().str.replace(' ','_')\n",
    "##KSADSdf['subjectlength']=KSADSdf.subject.str.len()\n",
    "##KSADSdf.loc[KSADSdf.subjectlength>10] #none, whew\n",
    "#KSADSdf.groupby('patienttype').count()\n",
    "#KSADSdf.groupby('event').count()\n",
    "\n",
    "#normalKt=KSADSdf.loc[(KSADSdf.event.isin(['V1','V2','V3'])) & (KSADSdf.patienttype=='T')][['subject','event']]\n",
    "#normalKp=KSADSdf.loc[(KSADSdf.event.isin(['V1','V2','V3'])) & (KSADSdf.patienttype=='P')][['subject','event']]\n",
    "\n",
    "#togetherinventory7=pd.merge(togetherinventory6,normalKt,left_on=['child_id','redcap_event'],right_on=['subject', 'event'],how='left',indicator=\"Curated_KSADS_T\")\n",
    "#togetherinventory7.Curated_KSADS_T=togetherinventory7.Curated_KSADS_T.str.replace('both','YES')\n",
    "#togetherinventory7.Curated_KSADS_T=togetherinventory7.Curated_KSADS_T.str.replace('left_only','NO')\n",
    "#togetherinventory7.loc[(togetherinventory7.Curated_KSADS_T=='NO') & (togetherinventory7.agetest<12),'Curated_KSADS_T']='NE AGE'\n",
    "#togetherinventory7.loc[~(togetherinventory7.redcap_event.isin(['V1','V2','V3'])),'Curated_KSADS_T']='NE'\n",
    "#togetherinventory7.loc[(togetherinventory7.Curated_KSADS_T=='NO') & (togetherinventory7.misscat___5=='1') & (togetherinventory7.missksads___1=='1'),'Curated_KSADS_T']='NE PM'\n",
    "#togetherinventory7.loc[(togetherinventory7.Curated_KSADS_T=='YES') & (togetherinventory7.misscat___5=='1') & (togetherinventory7.missksads___1=='1'),'Curated_KSADS_T']='YES BUT'\n",
    " \n",
    "      \n",
    "#togetherinventory8=pd.merge(togetherinventory7.drop(columns=['event','subject']),normalKp,left_on=['child_id','redcap_event'],right_on=['subject', 'event'],how='left',indicator=\"Curated_KSADS_P\")\n",
    "#togetherinventory8.Curated_KSADS_P=togetherinventory8.Curated_KSADS_P.str.replace('both','YES')\n",
    "#togetherinventory8.Curated_KSADS_P=togetherinventory8.Curated_KSADS_P.str.replace('left_only','NO')\n",
    "#togetherinventory8.loc[~(togetherinventory8.redcap_event.isin(['V1','V2','V3'])),'Curated_KSADS_P']='NE'\n",
    "#togetherinventory8.loc[(togetherinventory8.Curated_KSADS_P=='NO') & (togetherinventory8.misscat___5=='1') & (togetherinventory8.missksads___2=='1'),'Curated_KSADS_P']='NE PM'\n",
    "#togetherinventory8.loc[(togetherinventory8.Curated_KSADS_P=='YES') & (togetherinventory8.misscat___5=='1') & (togetherinventory8.missksads___2=='1'),'Curated_KSADS_P']='YES BUT'\n",
    "\n",
    "#togetherinventory8=togetherinventory8.drop(columns=['subject','event'])\n",
    "\n",
    "#togetherinventory8.columns\n",
    "\n",
    "togetherinventory8=togetherinventory6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENTED OUT BECAUSE KSADS NO LONGER STORED IN REDCAP -- ARCHIVED.  USE DATA FROM PREVIOUS VERSIONS OF INVENTORY\n",
    "\n",
    "#specialK=KSADSdf.loc[(KSADSdf.event.isin(['V1_MOOD','V2_MOOD','V3_MOOD']))].copy()\n",
    "#specialK.groupby('event').count()   \n",
    "#new2=specialK['event'].str.split(\"_\", 1, expand=True)\n",
    "#specialK['newevent']=new2[0].str.strip()\n",
    "#specialK.groupby('newevent').count()\n",
    "\n",
    "#specialKt=specialK.loc[(specialK.newevent.isin(['V1','V2','V3'])) & (specialK.patienttype=='T')][['subject','newevent']]\n",
    "#specialKp=specialK.loc[(specialK.newevent.isin(['V1','V2','V3'])) & (specialK.patienttype=='P')][['subject','newevent']]\n",
    "\n",
    "#specialKt.columns\n",
    "#togetherinventory8.columns\n",
    "#togetherinventory8.event_date=pd.to_datetime(togetherinventory8.event_date)\n",
    "\n",
    "#togetherinventory9=pd.merge(togetherinventory8,specialKt,left_on=['child_id','redcap_event'],right_on=['subject', 'newevent'],how='left',indicator=\"Curated_KSADS_MOOD_T\")\n",
    "#togetherinventory9.Curated_KSADS_MOOD_T=togetherinventory9.Curated_KSADS_MOOD_T.str.replace('both','YES')\n",
    "#togetherinventory9.Curated_KSADS_MOOD_T=togetherinventory9.Curated_KSADS_MOOD_T.str.replace('left_only','NO')\n",
    "#togetherinventory9.loc[(togetherinventory9.Curated_KSADS_MOOD_T=='NO') & (togetherinventory9.agetest<12),'Curated_KSADS_MOOD_T']='NE AGE'\n",
    "#togetherinventory9.loc[(togetherinventory9.Curated_KSADS_MOOD_T=='NO') & (togetherinventory9.event_date < '2020-8-1'),'Curated_KSADS_MOOD_T']='NE'\n",
    "#togetherinventory9.loc[~(togetherinventory9.redcap_event.isin(['V1','V2','V3'])),'Curated_KSADS_MOOD_T']='NE'\n",
    "#togetherinventory9.loc[(togetherinventory9.Curated_KSADS_MOOD_T=='NO') & (togetherinventory9.misscat___5=='1') & (togetherinventory9.missksads___1=='1'),'Curated_KSADS_MOOD_T']='NE PM'\n",
    "#togetherinventory9.loc[(togetherinventory9.Curated_KSADS_MOOD_T=='YES') & (togetherinventory9.misscat___5=='1') & (togetherinventory9.missksads___1=='1'),'Curated_KSADS_MOOD_T']='YES BUT'\n",
    "\n",
    "#togetherinventory9.columns\n",
    "\n",
    "#togetherinventory10=pd.merge(togetherinventory9.drop(columns=['newevent','subject']),specialKp,left_on=['child_id','redcap_event'],right_on=['subject', 'newevent'],how='left',indicator=\"Curated_KSADS_MOOD_P\")\n",
    "#togetherinventory10.Curated_KSADS_MOOD_P=togetherinventory10.Curated_KSADS_MOOD_P.str.replace('both','YES')\n",
    "#togetherinventory10.Curated_KSADS_MOOD_P=togetherinventory10.Curated_KSADS_MOOD_P.str.replace('left_only','NO')\n",
    "#togetherinventory10.loc[(togetherinventory10.Curated_KSADS_MOOD_P=='NO') & (togetherinventory10.event_date < '2020-8-1'),'Curated_KSADS_MOOD_P']='NE'\n",
    "#togetherinventory10.loc[~(togetherinventory10.redcap_event.isin(['V1','V2','V3'])),'Curated_KSADS_MOOD_P']='NE'\n",
    "#togetherinventory10.loc[(togetherinventory10.Curated_KSADS_MOOD_P=='NO') & (togetherinventory10.misscat___5=='1') & (togetherinventory10.missksads___1=='1'),'Curated_KSADS_MOOD_P']='NE PM'\n",
    "#togetherinventory10.loc[(togetherinventory10.Curated_KSADS_MOOD_P=='YES') & (togetherinventory10.misscat___5=='1') & (togetherinventory10.missksads___1=='1'),'Curated_KSADS_MOOD_P']='YES BUT'\n",
    "\n",
    "\n",
    "#togetherinventory10.columns\n",
    "#togetherinventory10.drop(columns=['subject','newevent'])\n",
    "\n",
    "togetherinventory10=togetherinventory8.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#togetherinventory10.event_date=pd.to_datetime(togetherinventory10.event_date)\n",
    "#togetherinventory10.loc[togetherinventory10.event_date < '2020-8-1']\n",
    "#togetherinventory10.event_date\n",
    "snapshotdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lastly get doubles\n",
    "print(doubles.columns)\n",
    "togetherinventory11=pd.merge(doubles,togetherinventory10,how='right',left_on='HCDid',right_on='parent_at_visit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(togetherinventory11.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################PPPPPPPP\n",
    "#extra PIN work for TOOLBOX parents of multiple children\n",
    "togetherinventory11['ParentPIN']=togetherinventory11.parent_at_visit.str.cat(togetherinventory11.redcap_event,sep=\"_\")\n",
    "togetherinventory11['ParentPIN_alt']=togetherinventory11.parent_at_V1.str.cat(togetherinventory11.redcap_event,sep=\"_\")\n",
    "togetherinventory11['ChildPIN']=togetherinventory11.child_id.str.cat(togetherinventory11.redcap_event,sep=\"_\")\n",
    "\n",
    "#merge in known X1 PINS\n",
    "Xlist=Xlist.rename(columns={'PIN':'ParentPIN','DateFinished':'ParentDateFinishedTLBX','subject':'parent_at_visit'})\n",
    "Xlist.loc[Xlist.ParentPIN.str.contains('X1'),'redcap_event']='V1'\n",
    "Xlist.loc[Xlist.ParentPIN.str.contains('V2'),'redcap_event']='V2'\n",
    "Xlist.loc[Xlist.ParentPIN.str.contains('X2'),'redcap_event']='V2'\n",
    "Xlist.loc[Xlist.ParentPIN.str.contains('X3'),'redcap_event']='V3'\n",
    "\n",
    "print(Xlist.drop(columns=['subjectlength','event']))\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0117324_V1','ParentPIN']=\"HCD3559977_X1\"\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0117324_V1','ParentDateFinishedTLBX']='1/19/2020 14:03'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0909761_V1','ParentPIN']=\"HCD3622655_X1\"\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0909761_V1','ParentDateFinishedTLBX']='8/24/19 12:53'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2499374_V1','ParentPIN']=\"HCD3918272_X1\"\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2499374_V1','ParentDateFinishedTLBX']='6/25/19 10:02'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1775266_V2','ParentPIN']='HCD4128753_X2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1775266_V2','ParentDateFinishedTLBX']='8/2/19 16:44'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0836356_V1','ParentPIN']='HCD3629467_X1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0836356_V1','ParentDateFinishedTLBX']='1/27/20 10:42'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0501830_V1','ParentPIN']='HCD5465776_X1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0501830_V1','ParentDateFinishedTLBX']='10/18/20 14:30'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2944066_V1','ParentPIN']='HCD4593073_X1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2944066_V1','ParentDateFinishedTLBX']='4/29/17 17:14'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1335339_V1','ParentPIN']='HCD3366461_X1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1335339_V1','ParentDateFinishedTLBX']='7/25/2021 12:22'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2156142_V1','ParentPIN']='HCD3379874_X1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2156142_V1','ParentDateFinishedTLBX']='3/12/19 16:09'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1681358_V1','ParentPIN']='HCD5744376_X1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1681358_V1','ParentDateFinishedTLBX']='8/8/2019 18:01'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0639455_V1','ParentPIN']='HCD5466980_X1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0639455_V1','ParentDateFinishedTLBX']='11/3/2019 12:08'\n",
    "\n",
    "\n",
    "#print(Xlist)\n",
    "\n",
    "#NEW INTEL MAKING ITS WAY THROUGH TRELLO (if empty, this code accounts for  known Xs :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cases where multiple parents came in for a particular visit and messed with the ability to track toolbox PINs\n",
    "#note that some of these might still be making their way through pipes to curated\n",
    "#if not in TLBXD, then make sure they get grabbed from endpoint. \n",
    "\n",
    "TLBXD.head()\n",
    "print(TLBXD.loc[TLBXD.subject.isin(['HCD5443261','HCD4982185','HCD5555474','HCD3429358','HCD5555474','HCD3044641','HCD5016242','HCD4351251','HCD4810257','HCD3404039','HCD4082048','HCD5443261'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cases where multiple parents came in for a particular visit or parents \n",
    "#came in for multiple children and messed with the ability to track toolbox PINs\n",
    "\n",
    "#HCD5555474_V1 is parent PIN associated with HCD0977576_V1 (both parents came in)\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0977576_V1','ParentPIN']='HCD5555474_V1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0977576_V1','ParentDateFinishedTLBX']='8/24/2018 18:21'\n",
    "\n",
    "#HCD0363743_V1 with HCD5443261_V1\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0363743_V1','ParentPIN']='HCD5443261_V1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0363743_V1','ParentDateFinishedTLBX']='12/19/2017 15:54'\n",
    "\n",
    "\n",
    "#HCD3044641_V1 not HCD5850476_V1 completed parent about self toolbox data due to injury...i.e. v1 split between two parents.\n",
    "#affected two subjects Toolbox's parent about self as context for child data: HCD2540042_V1 and HCD1893171_V1\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2540042_V1','ParentPIN']='HCD3044641_V1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2540042_V1','ParentDateFinishedTLBX']='8/11/18 14:36'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1893171_V1','ParentPIN']='HCD3044641_V1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1893171_V1','ParentDateFinishedTLBX']='8/11/18 14:36'\n",
    "\n",
    "#HCD4982185_V1 with HCD2944874_V1\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2944874_V1','ParentPIN']='HCD4982185_V1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2944874_V1','ParentDateFinishedTLBX']='2021-09-26 15:55:31'\n",
    "\n",
    "\n",
    "\n",
    "#discovered that parents were the same person so commenting this out - will correct HCD4810257_V2 id in curated\n",
    "##HCD4810257_V2 not HCD5562875_V2 completed parent about self for HCD2239247_V2 (visit split between two parents)\n",
    "#togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2239247_V2','ParentPIN']='HCD4810257_V2'\n",
    "#togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2239247_V2','ParentDateFinishedTLBX']='2019-08-26 09:19:53'\n",
    "\n",
    "#V1 to V2 PIN-mapping nonsense\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0843151_V1','ParentPIN']='HCD4620555_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0843151_V1','ParentDateFinishedTLBX']='6/11/2019  13:47:00'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1780663_V1','ParentPIN']='HCD3404039_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1780663_V1','ParentDateFinishedTLBX']='2019-10-16 15:47:33'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2980575_V1','ParentPIN']='HCD4046448_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2980575_V1','ParentDateFinishedTLBX']='5/5/2019  10:00:00'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2095754_V1','ParentPIN']='HCD3721859_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2095754_V1','ParentDateFinishedTLBX']='6/25/2019  14:25:25'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1872062_V1','ParentPIN']='HCD5314250_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1872062_V1','ParentDateFinishedTLBX']='7/26/2019  14:18:04'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1194751_V1','ParentPIN']='HCD5857793_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1194751_V1','ParentDateFinishedTLBX']='10/17/2019  10:56:00'\n",
    "\n",
    "\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0030413_V1','ParentPIN']='HCD5027247_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0030413_V1','ParentDateFinishedTLBX']='10/26/2019  08:19:43'\n",
    "\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0318435_V1','ParentPIN']='HCD5027247_V3'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0318435_V1','ParentDateFinishedTLBX']='12/14/2020  15:50:49'\n",
    "\n",
    "\n",
    "\n",
    "#this one on endpoint but not in curated yet as of 36 - adding to list to grab\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1328241_V2','ParentPIN']='HCD5016242_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1328241_V2','ParentDateFinishedTLBX']='2020-01-25 09:10:57'\n",
    "\n",
    "#this one not yet pulled into endpoing as of round 28 - adding to list to grab\n",
    "#HCD4351251_V1 is parent PIN associated with HCD2373958_V1 even though other parent came in (both parents came in)\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2373958_V1','ParentPIN']='HCD4351251_V1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2373958_V1','ParentDateFinishedTLBX']='2019-12-19 18:47:35'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2888789_V1','ParentPIN']='HCD4082048_V1'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2888789_V1','ParentDateFinishedTLBX']='2018-09-24 09:39:51'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0363743_V2','ParentPIN']='HCD5443261_V2'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0363743_V2','ParentDateFinishedTLBX']='2019-03-11 17:58:19'\n",
    "\n",
    "#2nd parents at a particular visit above get set to yes\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0977576_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2540042_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1893171_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2239247_V2','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1780663_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1194751_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD1328241_V2','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2373958_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2888789_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0363743_V2','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD2944874_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "togetherinventory11.loc[togetherinventory11.ChildPIN=='HCD0363743_V1','Curated_TLBX_ParentPIN']='YES'\n",
    "\n",
    "#singletons where  walking test was rescored and got a new date which  makes it look like a 2017 test was administered in 2021 (important to know about if you want to filter by DateDiff variable)\n",
    "togetherinventory11.loc[togetherinventory11.ParentPIN=='HCD3324849_V1','ParentDateFinishedTLBX']='6/22/17 10:25'\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ParentPIN=='HCD5604259_V1','ParentDateFinishedTLBX']='7/18/17 10:48'\n",
    "\n",
    "#cases where SHOULD be an X but it didn't happen are handled\n",
    "#after the HCD child and HCD 18+ merge at end of this notebook with other NEs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanup of PINs where event was FU or something.\n",
    "togetherinventory11.loc[~(togetherinventory11.redcap_event.isin(['V1','V2','V3'])),'ParentPIN']=''\n",
    "togetherinventory11.loc[~(togetherinventory11.redcap_event.isin(['V1','V2','V3'])),'ParentPIN_alt']=''\n",
    "togetherinventory11.loc[~(togetherinventory11.redcap_event.isin(['V1','V2','V3'])),'ChildPIN']=''\n",
    "\n",
    "\n",
    "misscols=['toolbox_complete',\n",
    "       'remote_toolbox_emotion_complete', 'misstoolbox___1', 'misstoolbox___2',\n",
    "       'misstoolbox___3',  'misscat___3',\n",
    "       'misscat___9', 'misscat___5', 'data_status', 'misstoolboxc',\n",
    "       'misstoolboxpc', 'misstoolboxpp', 'general_note', 'misscog___1',\n",
    "       'misscog___2', 'misscog___3', 'misscogq', 'misscogupen', 'misscogdd',\n",
    "       'missksads___1', 'missksads___2', 'missksads_c', 'missksads_p']\n",
    "\n",
    "print(\"BEFORE DE-DUP\")\n",
    "print(togetherinventory11.shape)\n",
    "\n",
    "togetherinventory11.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "\n",
    "print(\"After DE-DUP\")\n",
    "print(togetherinventory11.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create days since first date and parent child tlbx date diff\n",
    "togetherinventory11.event_date=pd.to_datetime(togetherinventory11.event_date)\n",
    "togetherinventory11.ParentDateFinishedTLBX=pd.to_datetime(togetherinventory11.ParentDateFinishedTLBX)\n",
    "\n",
    "togetherinventory11.loc[togetherinventory11.ChildDateFinishedTLBX.astype('str').str.contains('####'),'ChildDateFinishedTLBX']=''\n",
    "togetherinventory11.ChildDateFinishedTLBX=pd.to_datetime(togetherinventory11.ChildDateFinishedTLBX)\n",
    "\n",
    "togetherinventory11['ParentChildTLBXdaydiff']=(togetherinventory11.ParentDateFinishedTLBX - togetherinventory11.ChildDateFinishedTLBX).dt.days\n",
    "\n",
    "date1=togetherinventory11.sort_values(['child_id','event_date'])[['child_id','event_date']].drop_duplicates(subset=['child_id'],keep='first').rename(columns={'event_date':'first_date'})\n",
    "print(date1[['child_id','first_date']].head())\n",
    "togetherinventory12=pd.merge(togetherinventory11,date1,how='left',on='child_id')\n",
    "\n",
    "togetherinventory12['daysfromtime0']=(togetherinventory12.event_date - togetherinventory12.first_date).dt.days\n",
    "#togetherinventory12['daysfromtime0'].dt.days\n",
    "print(togetherinventory12.daysfromtime0.head())\n",
    "\n",
    "\n",
    "keeplist=['id','dob', 'redcap_id_parent','site','psuedo_guid','HCAid', 'HCDid', 'parent_at_visit', 'parent_at_V1', 'child_id',\n",
    "        'race',  'ethnic_group', 'M/F', 'DB_Source','redcap_event',  'event_date', 'daysfromtime0', 'event_age', 'event_register', \n",
    "        'height','weight','bpressure',\n",
    "        'Curated_TLBX_ChildPIN', 'Curated_TLBX_ParentPIN',\n",
    "       'Curated_PennCNP', 'Curated_Eprime',\n",
    "       'Curated_Q',   'ChildDateFinishedTLBX','ParentDateFinishedTLBX', \n",
    "          'ParentChildTLBXdaydiff','ParentPIN','ChildPIN',      \n",
    "       'redcap_event_name'] \n",
    "#'Curated_KSADS_T',  'Curated_KSADS_P',\n",
    "#'Curated_KSADS_MOOD_T', 'Curated_KSADS_MOOD_P', \n",
    "\n",
    "keepcols=keeplist+misscols #need to keep dob until the very end because of NDA age calculation\n",
    "\n",
    "\n",
    "parentchild=togetherinventory12.copy()\n",
    "print(parentchild.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCD 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCD18+\n",
    "HCD18df=getreport(data=data18)\n",
    "HCD18df.head()\n",
    "hcpd18=HCD18df.loc[HCD18df.redcap_event_name=='visit_arm_1'].copy()\n",
    "hcpd18.head()\n",
    "hcpd18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcpd18.sub_race___10=hcpd18.sub_race___10.astype(int)\n",
    "hcpd18.sub_race___11=hcpd18.sub_race___11.astype(int)\n",
    "hcpd18.sub_race___12=hcpd18.sub_race___12.astype(int)\n",
    "hcpd18.sub_race___14=hcpd18.sub_race___14.astype(int)\n",
    "hcpd18.sub_race___18=hcpd18.sub_race___18.astype(int)\n",
    "hcpd18.sub_race___25=hcpd18.sub_race___25.astype(int)\n",
    "hcpd18.sub_race___99=hcpd18.sub_race___99.astype(int)\n",
    "#.str.strip().replace('','0')\n",
    "\n",
    "hcpd18['sumcheckedrace']=hcpd18[['sub_race___10','sub_race___11','sub_race___12','sub_race___14','sub_race___18','sub_race___25']].sum(axis=1)\n",
    "\n",
    "#HCPD18 folks can select multiple race options (checkbox)...need to convert those to 'more than one race' category of mutually exclusive version of race variable required by NDAR\n",
    "hcpd18.loc[(hcpd18.sumcheckedrace==1) & (hcpd18.sub_race___10==1),'racial']=5\n",
    "hcpd18.loc[(hcpd18.sumcheckedrace==1) & (hcpd18.sub_race___11==1),'racial']=3\n",
    "hcpd18.loc[(hcpd18.sumcheckedrace==1) & (hcpd18.sub_race___12==1),'racial']=1\n",
    "hcpd18.loc[(hcpd18.sumcheckedrace==1) & (hcpd18.sub_race___14==1),'racial']=4\n",
    "hcpd18.loc[(hcpd18.sumcheckedrace==1) & (hcpd18.sub_race___18==1),'racial']=2\n",
    "hcpd18.loc[(hcpd18.sumcheckedrace==1) & (hcpd18.sub_race___25==1),'racial']=6\n",
    "hcpd18.loc[(hcpd18.sumcheckedrace==0) & (hcpd18.sub_race___99==1),'racial']=99\n",
    "hcpd18.loc[hcpd18.sumcheckedrace>=2,'racial']=6\n",
    "\n",
    "#hcpd18[['sub_race___10','sub_race___11','sub_race___12','sub_race___14','sub_race___18','sub_race___25','sumcheckedrace','racial']].head(20)\n",
    "hcpd18.loc[hcpd18.racial==1,'race']='American Indian/Alaska Native'\n",
    "hcpd18.loc[hcpd18.racial==2,'race']='Asian'\n",
    "hcpd18.loc[hcpd18.racial==3,'race']='Black or African American'\n",
    "hcpd18.loc[hcpd18.racial==4,'race']='Hawaiian or Pacific Islander'\n",
    "hcpd18.loc[hcpd18.racial==5,'race']='White'\n",
    "hcpd18.loc[hcpd18.racial==6,'race']='More than one race'\n",
    "hcpd18.loc[hcpd18.racial==99,'race']='Unknown or not reported'\n",
    "\n",
    "\n",
    "hcpd18.loc[hcpd18.sub_latino=='1','ethnic_group']='Hispanic or Latino'\n",
    "hcpd18.loc[hcpd18.sub_latino=='0','ethnic_group']='Not Hispanic or Latino'\n",
    "hcpd18.loc[hcpd18.sub_latino=='9','ethnic_group']='Unknown or not reported'\n",
    "\n",
    "hcpd18[['sub_race___10','sub_race___11','sub_race___12','sub_race___14','sub_race___18','sub_race___25','sumcheckedrace','racial','race']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing because excluded. all good.\n",
    "hcpd18.loc[hcpd18.race.isnull()==True]\n",
    "hcpd18.loc[hcpd18.ethnic_group.isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allevents=hcpd18[['dob','id','subject_id','gender','site','race','ethnic_group','psuedo_guid']].replace({'site':\n",
    "                                      {'1': 'MGH/Harvard', '2':'UCLA', '3':'UMinn', '4':'WashU'}}).copy()\n",
    "allevents['M/F']=allevents.replace({'gender':\n",
    "                                           {'1':'M',\n",
    "                                            '2':'F'}})['gender']\n",
    "\n",
    "#cpature the flags\n",
    "new = allevents['subject_id'].str.split(\"_\", 1, expand=True)\n",
    "allevents['subject'] = new[0].str.strip()\n",
    "allevents['flagged'] = new[1].str.strip()\n",
    "\n",
    "#propagate all events fields throughout rest of events\n",
    "HCD18df2=pd.merge(allevents,HCD18df.drop(columns=['subject_id','dob','gender','psuedo_guid','site','sub_race___12', 'sub_race___18', 'sub_race___11',\n",
    "       'sub_race___14', 'sub_race___10', 'sub_race___25', 'sub_race___99',\n",
    "       'sub_latino']),how='right',on='id')\n",
    "HCD18df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCD18df2.flagged.unique()\n",
    "HCD18df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#removed flagged individuals\n",
    "print(HCD18df2.shape)\n",
    "HCD18df2.loc[(HCD18df2.flagged.isnull()==False)][['subject_id','age']].sort_values('age').drop_duplicates(subset='subject_id',keep='last').to_csv('HCD18exclusions.csv',index=False)\n",
    "HCD18df3=HCD18df2.loc[(HCD18df2.flagged.isnull()==True)].copy()\n",
    "print(HCD18df3.shape)\n",
    "\n",
    "#recode event names\n",
    "HCD18df3['redcap_event']=HCD18df3.replace({'redcap_event_name':\n",
    "                                           {'visit_arm_1':'V1',\n",
    "                                            'follow_up_arm_1':'F1',\n",
    "                                            'covid_arm_1':'Covid',\n",
    "                                            'covid_2_arm_1':'Covid2'\n",
    "                                           }})['redcap_event_name'].copy()\n",
    "\n",
    "\n",
    "HCD18df3.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCD 18 Event Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intake_date age v3_date age_v3 visit_type visit visit7 visit8 covid_dt covid18_dt covid18_age\n",
    "#visit_arm_1\n",
    "#follow_up_arm_1\n",
    "#covid_arm_1\n",
    "#covid_2_arm_1\n",
    "HCD18df3['event_date']=''\n",
    "HCD18df3['event_age']=''\n",
    "HCD18df3['event_register']=''\n",
    "\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['V1']),'event_date']=HCD18df3.intake_date\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['V1']),'event_age']=HCD18df3.age\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['V1']),'event_register']=HCD18df3.visit_type\n",
    "\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['F1']),'event_date']=HCD18df3.v3_date\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['F1']),'event_age']=HCD18df3.age_v3\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['F1']),'event_register']=HCD18df3.visit\n",
    "\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['Covid']),'event_date']=HCD18df3.covid_dt\n",
    "#HCD18df3.loc[HCD18df3.redcap_event.isin(['Covid']),'event_age']=HCD18df3.age\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['Covid']),'event_register']=HCD18df3.visit7\n",
    "\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['Covid2']),'event_date']=HCD18df3.covid18_dt\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['Covid2']),'event_age']=HCD18df3.covid18_age\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['Covid2']),'event_register']=HCD18df3.visit8\n",
    "\n",
    "#HCAdf2.loc[HCAdf2['event_date'].str.contains('2929'),'event_date']=''\n",
    "HCD18df3['alt_age']=(pd.to_datetime(HCD18df3['event_date'])-pd.to_datetime(HCD18df3['dob'])).dt.days/365.2425\n",
    "HCD18df3.reset_index(inplace=True)\n",
    "\n",
    "#assign missing ages to Covid Arms\n",
    "HCD18df3.loc[HCD18df3.redcap_event.isin(['Covid']),'event_age']=HCD18df3.alt_age\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty rows\n",
    "print(HCD18df3.shape)\n",
    "HCD18df3=HCD18df3.loc[~(HCD18df3.redcap_event.isin(['Covid']) & (HCD18df3.event_date=='') & (HCD18df3.covid_complete=='0'))]\n",
    "print(HCD18df3.shape)\n",
    "HCD18df4=HCD18df3.loc[~((HCD18df3.event_register=='8') & (HCD18df3.event_date=='') & (HCD18df3.covid_19_questionnaire_youth_complete=='0'))].copy()\n",
    "print(HCD18df4.shape)\n",
    "HCD18df4.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCD18df4[['site','redcap_event','id','subject','event_date','M/F','event_age','race', 'ethnic_group','intake_date', 'visit_type', 'age', 'visit', 'v3_date', 'age_v3',\n",
    "#       'visit7', 'visit8', 'covid_dt',  'covid18_dt',\n",
    "#       'covid18_age', 'alt_age','covid_19_questionnaire_youth_complete', 'covid_complete']].sort_values(['site','redcap_event']).to_csv('hcd18test.csv',index=False)\n",
    "#        ]].head(10)\n",
    "#1, Scan | 2, REDCap | 3, Toolbox | 9, Cognitive Testing | 5, KSADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLBXD.head()\n",
    "HCD18df4.head()\n",
    "HCD18df4.loc[HCD18df4.redcap_event.isin(['V1'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCD 18 Curated_* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENTING OUT KSADS BECAUSE KSADS NO LONGER IN REDCAP and cleaned format is different.  USE EARLIER INVENTORY DATA\n",
    "\n",
    "HCD18df4.groupby('redcap_event').count()\n",
    "HCD18df4.event_date=pd.to_datetime(HCD18df4.event_date)\n",
    "\n",
    "togetherinventory=pd.merge(HCD18df4,TLBXD,how='left',left_on=['subject','redcap_event'],right_on=['subject','event'],indicator='Curated_TLBX').copy()\n",
    "togetherinventory.Curated_TLBX=togetherinventory.Curated_TLBX.str.replace('both','YES')\n",
    "togetherinventory.Curated_TLBX=togetherinventory.Curated_TLBX.str.replace('left_only','NO')\n",
    "togetherinventory.loc[~(togetherinventory.redcap_event.isin(['V1'])),'Curated_TLBX']='NE'\n",
    "togetherinventory=togetherinventory.rename(columns={'DateFinished':'DateFinishedTLBX'}).copy()\n",
    "togetherinventory=togetherinventory.drop(columns=['event']).copy()\n",
    "\n",
    "togetherinventory2=pd.merge(togetherinventory,pennHCD,left_on=['subject','redcap_event'],right_on=['subid','assessment'],how='left',indicator='Curated_PennCNP').copy()\n",
    "togetherinventory2.Curated_PennCNP=togetherinventory2.Curated_PennCNP.str.replace('both','YES')\n",
    "togetherinventory2.Curated_PennCNP=togetherinventory2.Curated_PennCNP.str.replace('left_only','NO')\n",
    "togetherinventory2.loc[~(togetherinventory2.redcap_event.isin(['V1'])),'Curated_PennCNP']='NE'\n",
    "togetherinventory2.loc[(togetherinventory2.Curated_PennCNP=='NO') & (togetherinventory2.misscat___9=='1') & (togetherinventory2.misscog___2=='1'),'Curated_PennCNP']='NE PM'\n",
    "togetherinventory2.loc[(togetherinventory2.Curated_PennCNP=='YES') & (togetherinventory2.misscat___9=='1') & (togetherinventory2.misscog___2=='1'),'Curated_PennCNP']='YES BUT'\n",
    "togetherinventory2=togetherinventory2.drop(columns=['subid','assessment']).copy()\n",
    "\n",
    "togetherinventory3=pd.merge(togetherinventory2,Qdf2,left_on=['subject','redcap_event'],right_on=['subjectid', 'event'],how='left',indicator=\"Curated_Q\").copy()\n",
    "togetherinventory3.Curated_Q=togetherinventory3.Curated_Q.str.replace('both','YES')\n",
    "togetherinventory3.Curated_Q=togetherinventory3.Curated_Q.str.replace('left_only','NO')\n",
    "togetherinventory3.loc[~(togetherinventory3.redcap_event.isin(['V1'])),'Curated_Q']='NE'\n",
    "togetherinventory3.loc[(togetherinventory3.Curated_Q=='NO') & (togetherinventory3.misscat___9=='1') & (togetherinventory3.misscog___1=='1'),'Curated_Q']='NE PM'\n",
    "togetherinventory3.loc[(togetherinventory3.Curated_Q=='YES') & (togetherinventory3.misscat___9=='1') & (togetherinventory3.misscog___1=='1'),'Curated_Q']='YES BUT'\n",
    "togetherinventory3=togetherinventory3.drop(columns=['subjectid', 'event']).copy()\n",
    "\n",
    "\n",
    "#togetherinventory4=pd.merge(togetherinventory3,normalKt,left_on=['subject','redcap_event'],right_on=['subject', 'event'],how='left',indicator=\"Curated_KSADS_T\").copy()\n",
    "#togetherinventory4.Curated_KSADS_T=togetherinventory4.Curated_KSADS_T.str.replace('both','YES')\n",
    "#togetherinventory4.Curated_KSADS_T=togetherinventory4.Curated_KSADS_T.str.replace('left_only','NO')\n",
    "#togetherinventory4.loc[~(togetherinventory4.redcap_event.isin(['V1'])),'Curated_KSADS_T']='NE'\n",
    "#togetherinventory4['Curated_KSADS_P']='NE AGE'\n",
    "#togetherinventory4.loc[(togetherinventory4.Curated_KSADS_T=='NO') & (togetherinventory7.misscat___5=='1'),'Curated_KSADS_T']='NE PM'\n",
    "#togetherinventory4.loc[(togetherinventory4.Curated_KSADS_T=='YES') & (togetherinventory7.misscat___5=='1'),'Curated_KSADS_T']='YES BUT'\n",
    "#togetherinventory4=togetherinventory4.drop(columns=['event']).copy()\n",
    " \n",
    "#PM=['HCD0051825_V1']\n",
    "#togetherinventory4.loc[(togetherinventory4.Curated_KSADS_T=='NO') & (togetherinventory4.subject=='HCD0051825'),'Curated_KSADS_T']='NE PM'\n",
    "\n",
    "    \n",
    "#togetherinventory5=pd.merge(togetherinventory4,specialKt,left_on=['subject','redcap_event'],right_on=['subject', 'newevent'],how='left',indicator=\"Curated_KSADS_MOOD_T\").copy()\n",
    "#togetherinventory5.Curated_KSADS_MOOD_T=togetherinventory5.Curated_KSADS_MOOD_T.str.replace('both','YES')\n",
    "#togetherinventory5.Curated_KSADS_MOOD_T=togetherinventory5.Curated_KSADS_MOOD_T.str.replace('left_only','NO')\n",
    "#togetherinventory5.loc[(togetherinventory5.Curated_KSADS_MOOD_T=='NO') & (togetherinventory5.event_date < '2020-8-1'),'Curated_KSADS_MOOD_T']='NE'\n",
    "#togetherinventory5.loc[~(togetherinventory5.redcap_event.isin(['V1'])),'Curated_KSADS_MOOD_T']='NE'\n",
    "#togetherinventory5['Curated_KSADS_MOOD_P']='NE AGE'\n",
    "#togetherinventory5.loc[(togetherinventory5.Curated_KSADS_MOOD_T=='NO') & (togetherinventory5.misscat___5=='1') ,'Curated_KSADS_MOOD_T']='NE PM'\n",
    "#togetherinventory5.loc[(togetherinventory5.Curated_KSADS_MOOD_T=='YES') & (togetherinventory5.misscat___5=='1'),'Curated_KSADS_MOOD_T']='YES BUT'\n",
    "\n",
    "togetherinventory5=togetherinventory3.copy()\n",
    "\n",
    "togetherinventory5['Curated_Eprime']='NE AGE'\n",
    "#[['id','site', \n",
    "#'subject', 'flagged','misscat___3','data_status', 'misstoolbox', 'general_note','_merge',\n",
    "#       'redcap_event', 'event_date', 'event_age', 'event_register']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "togetherinventory5['DB_Source']='teen'\n",
    "\n",
    "##create days since first date\n",
    "togetherinventory5.event_date=pd.to_datetime(togetherinventory5.event_date)\n",
    "\n",
    "date1=togetherinventory5.sort_values(['subject','event_date'])[['subject','event_date']].drop_duplicates(subset=['subject'],keep='first').rename(columns={'event_date':'first_date'})\n",
    "print(date1[['subject','first_date']].head())\n",
    "togetherinventory6=pd.merge(togetherinventory5,date1,how='left',on='subject')\n",
    "\n",
    "togetherinventory6['daysfromtime0']=(togetherinventory6.event_date - togetherinventory6.first_date).dt.days\n",
    "#togetherinventory6['daysfromtime0'].days()\n",
    "print(togetherinventory6.daysfromtime0.head())\n",
    "\n",
    "\n",
    "#togetherinventory.loc[togetherinventory.redcap_event.isin(['V1'])].to_csv('hcd18TLBXinventory.csv',index=False)\n",
    "togetherinventory6.columns\n",
    "reorder=['id',  'site', 'psuedo_guid','race',   'ethnic_group', 'M/F', 'subject', 'height', 'weight', 'bpressure',\n",
    "         'redcap_event', 'event_date', 'dob','event_age','alt_age','daysfromtime0',\n",
    "       'event_register',  'Curated_TLBX','DateFinishedTLBX','Curated_PennCNP', 'Curated_Q', 'Curated_Eprime','DB_Source',\n",
    "         'redcap_event_name',\n",
    "        'misscat___3', 'misscat___9',\n",
    "       'misscat___5', 'misstoolbox', 'general_note',\n",
    "       'misscog___1', 'misscog___2', 'misscogq', 'misscogupen',\n",
    "       'missssaga']\n",
    "#'Curated_KSADS_T',\n",
    "#        'Curated_KSADS_MOOD_T', 'Curated_KSADS_P',\n",
    "#        'Curated_KSADS_MOOD_P',\n",
    "\n",
    "teens=togetherinventory6.copy()\n",
    "#teens[reorder].to_csv('hcd18_Inventory'+snapshotdate+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teens[reorder].columns)\n",
    "print(teens.columns)\n",
    "print(parentchild[keeplist+misscols].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teens.subject_id\n",
    "#teens.loc[teens.subject_id=='HCD0671956']\n",
    "#teens.loc[teens.subject_id]#.str.contains('HCD0671956')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put HCD-child and HCD-18+ together\n",
    "\n",
    "hcdconcat=pd.concat([teens[reorder],parentchild[keeplist+misscols]],sort=False)\n",
    "\n",
    "\n",
    "hcdconcat=hcdconcat.reset_index()\n",
    "hcdconcat.loc[hcdconcat.subject.isnull()==True,'subject']=hcdconcat.child_id\n",
    "hcdconcat.loc[hcdconcat.Curated_TLBX.isnull()==True,'Curated_TLBX']=hcdconcat.Curated_TLBX_ChildPIN\n",
    "hcdconcat.loc[hcdconcat.DateFinishedTLBX.isnull()==True,'DateFinishedTLBX']=hcdconcat.ChildDateFinishedTLBX\n",
    "\n",
    "hcdconcat=hcdconcat.rename(columns={'Curated_TLBX_ParentPIN':'Curated_TLBX_Parent'})\n",
    "hcdconcat['PIN']=hcdconcat.subject.str.cat(hcdconcat.redcap_event,sep=\"_\")\n",
    "\n",
    "\n",
    "hcdconcat.loc[~(hcdconcat.redcap_event.isin(['V1','V2','V3'])),'PIN']=''\n",
    "#hcdconcat.loc[(hcdconcat.DB_Source=='teen') & (hcdconcat.redcap_event=='F1'),'PIN'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Curated_* info for Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toolbox 'NE BUTs' (e.g. permanently missing data - needed to pool all HCD sources before this was possible)\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD2730249') & (hcdconcat.ParentPIN=='HCD4511146_V3'),'Curated_TLBX_Parent']='NE PM'\n",
    "hcdconcat.loc[hcdconcat.ParentPIN=='HCD5164156_V1','Curated_TLBX_Parent']='NE PM'\n",
    "hcdconcat.loc[hcdconcat.PIN=='HCD2731049_V3','Curated_TLBX']='NE PM'\n",
    "hcdconcat.loc[hcdconcat.ParentPIN=='HCD3883178_V3','Curated_TLBX_Parent']='NE PM'              \n",
    "hcdconcat.loc[hcdconcat.PIN=='HCD2828569_V3','Curated_TLBX']='NE PM'\n",
    "hcdconcat.loc[hcdconcat.ParentPIN=='HCD3736771_V3','Curated_TLBX_Parent']='NE PM'\n",
    "hcdconcat.loc[hcdconcat.PIN=='HCD1769978_V1','Curated_TLBX']='NE PM'\n",
    "\n",
    "\n",
    "hcdconcat.loc[hcdconcat.PIN.isin(['HCD2199867_V1','HCD0134526_V3','HCD0288250_V3','HCD0259546_V3','HCD0181838_V3','HCD0598366_V3','HCD0024418_V3','HCD0956871_V3','HCD2295762_V3','HCD0113316_V3','HCD1655458_V3','HCD2485666_V3','HCD1227740_V3','HCD0802440_V3']),'Curated_TLBX']='NE PM'\n",
    "hcdconcat.loc[hcdconcat.ParentPIN.isin(['HCD4819275_V3','HCD3724663_V3','HCD3718163_V3','HCD4248763_V3','HCD4335657_V3','HCD4763880_V3','HCD3404039_V3','HCD3760465_V3','HCD3721859_V3','HCD5952989_V3','HCD5337666_V1']),'Curated_TLBX_Parent']='NE PM'\n",
    "   \n",
    "hcdconcat.loc[hcdconcat.PIN.isin(['HCD0869371_V3','HCD0777265_V3','HCD1852056_V1','HCD1880162_V3']),'Curated_TLBX']='NE PM'\n",
    "hcdconcat.loc[hcdconcat.ParentPIN.isin(['HCD3915771_V1','HCD3663568_V1','HCD5060245_V1','HCD5549176_V2', 'HCD5549176_V2','HCD5549176_V2','HCD4451558_V2','HCD5060245_V1','HCD3644362_V3','HCD5212040_V2','HCD5337666_V1','HCD4815065_V3','HCD5186570_V3','HCD4919784_V2','HCD5944384_V1','HCD4033843_V1','HCD5664984_V1','HCD4719372_V2','HCD3380152_V1']),'Curated_TLBX_Parent']='NE PM'\n",
    "#Note: HCA7424873_V1 = HCD5337666_V1, however Parent is of child who had failure to complete.  Listed as NE PM above, and NE PM here in case they show up again, but parent isnt in inventory.\n",
    "               \n",
    "               \n",
    "#would be X1s who didn't complete  Toolbox for second child.\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD0927056') & (hcdconcat.ParentPIN=='HCD5374369_V1'),'Curated_TLBX_Parent']='NE X'\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD0927056') & (hcdconcat.ParentPIN=='HCD5374369_V1'),'ParentDateFinishedTLBX']=''\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD0927056') & (hcdconcat.ParentPIN=='HCD5374369_V1'),'ParentChildTLBXdaydiff']=''\n",
    "\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD1188756') & (hcdconcat.ParentPIN=='HCD4891990_V1'),'Curated_TLBX_Parent']='NE X'\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD1188756') & (hcdconcat.ParentPIN=='HCD4891990_V1'),'ParentDateFinishedTLBX']=''\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD1188756') & (hcdconcat.ParentPIN=='HCD4891990_V1'),'ParentChildTLBXdaydiff']=''\n",
    "\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD2642858') & (hcdconcat.ParentPIN=='HCD4679689_V1'),'Curated_TLBX_Parent']='NE X'\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD2642858') & (hcdconcat.ParentPIN=='HCD4679689_V1'),'ParentDateFinishedTLBX']=''\n",
    "hcdconcat.loc[(hcdconcat.subject=='HCD2642858') & (hcdconcat.ParentPIN=='HCD4679689_V1'),'ParentChildTLBXdaydiff']=''\n",
    "\n",
    "\n",
    "#NE Double\n",
    "hcdconcat.loc[hcdconcat.ParentPIN.isin(['HCD4064248_V1','HCD5896703_V1','HCD5937387_V1','HCD5342154_V1','HCD5375472_V2','HCD5177771_V1']),'Curated_TLBX_Parent']='SEE DOUBLE' # double winner=HCA9268996\n",
    "\n",
    "#teen parents \n",
    "hcdconcat.loc[hcdconcat.DB_Source=='teen','Curated_TLBX_Parent']='NE AGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "hcdconcat.Curated_Eprime.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=hcdconcat.copy()\n",
    "test.loc[test.redcap_event.isin(['Covid','Covid2','F1']),'Curated_Eprime']='NE'\n",
    "test.Curated_Eprime.value_counts()\n",
    "\n",
    "#test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registered events that didnt happen - consider removing from REDCap altogether\n",
    "#this one is registered in parent database only...\n",
    "hcdconcat=hcdconcat.loc[~(hcdconcat.PIN.isin(['HCD0406230_V2']))].copy()\n",
    "\n",
    "#get list of legit HCD subjects\n",
    "hcdconcat.columns\n",
    "a=pd.DataFrame(hcdconcat.loc[hcdconcat.ParentPIN.isnull()==False,'ParentPIN'])\n",
    "a.head()\n",
    "b=pd.DataFrame(a.loc[~(a.ParentPIN==\"\")])\n",
    "p=list(b.ParentPIN.str[:10].unique()) #.ParentPin#.str[:10]\n",
    "allsubs=list(hcdconcat.subject.unique())+list(hcdconcat.parent_at_V1.unique())+list(hcdconcat.parent_at_visit.unique())+p\n",
    "len(allsubs)\n",
    "\n",
    "subsubs=list(hcdconcat.subject.unique())\n",
    "#subsubs\n",
    "\n",
    "hcdconcat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'HCD4810257' in list(hcdconcat.parent_at_visit.unique())\n",
    "#b.ParentPIN.str[:10].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TLBXD IDS that dont exist in REDCap: create trello card to investigate and possibly drop from curated\")\n",
    "for i in TLBXD.subject:\n",
    "    if i in allsubs:\n",
    "        pass\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "\n",
    "print(\"Penn IDS that dont exist in REDCap: create trello card to investigate and set unusable in curated\")\n",
    "for i in pennHCD.subid:\n",
    "    if i in subsubs:\n",
    "        pass\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "print(\"Q-int IDs that doen't exist in REDCap: create trello cards to investigate and set unusable in curated\")\n",
    "for i in Qdf2.loc[Qdf2.subjectid.str.contains('HCD'),'subjectid']:\n",
    "    if i in subsubs:\n",
    "        pass\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "#ravvos=pd.merge(HCAdf3,Qdf2,left_on=['subject'],right_on=['subjectid'],how='right',indicator=\"Ravvos\")\n",
    "#print(ravvos.loc[(ravvos.Ravvos=='right_only') & ~(ravvos.subjectid.str.contains('HCD'))][['subjectid']])\n",
    "\n",
    "#print(\"SSAGA IDs that don't exist in REDCap: create trello cards to investigate and drop from curated\")\n",
    "#ssagos=pd.merge(HCAdf3,ssaga,left_on=['subject'],right_on=['hcpa_id'],how='right',indicator=\"Ssagos\")\n",
    "#print(ssagos.loc[(ssagos.Ssagos=='right_only')][['hcpa_id']])\n",
    "##note that HCA7297488 and HCA8680189 and HCA8363682 withdrew.  SSAGA database doesnt say as much but pre-release \n",
    "##folders already account for this information because they refer to the HCPA redcap database as \n",
    "##gold standard for withdrawn status is appendix to name in HCPA database.    \n",
    "\n",
    "#HCD0661448 DNR (18+)\n",
    "#HCD0671956 FTC (18+)\n",
    "#HCD0971261 withdrew (child) - double check that mask drops these prior to Prerelease\n",
    "#HCD1027530 excluded (child) - ''\n",
    "#HCD1616953 withdrew (child) - ''\n",
    "#HCD1703039 excluded (child) - ''\n",
    "#HCD1727558 withdrew (child) - ''\n",
    "#HCD2113528 excluded (child) - ''\n",
    "#HCD2384761 withdrew (child) - ''\n",
    "#HCD2557463 withdrew (child) - ''\n",
    "\n",
    "#HCD3367766 appears to be a parent of a DNR child - > remove from curated?  \n",
    "#HCD3377971 is parent of child HCD2199867 according to parent database, but HCD2199867 is FTC -> remove from curated and make sure child is removed, too?  \n",
    "\n",
    "#HCD3563665 parent of three children, all of whom were withdrawn, excluded, or DNR\n",
    "\n",
    "#HCD4810257 is accidental alias of parent...in progress: replace HCD4810257_V2 Pin with HCD5562875_V2 in curated\n",
    "\n",
    "#HCD5681681 and HCD5750742 are both listed as double winners, but cant find record of their role as parents in REDCap databse. \n",
    "\n",
    "###MAKE SURE THIS LIST IS GONE FROM PRERELEASE!!!\n",
    "\n",
    "\n",
    "\n",
    "#DO NOT FILTER  HCD3429964. Is parent of one DNR and also an HCA and sister of another HCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup\n",
    "#hcdconcat2=hcdconcat.copy()\n",
    "#hcdconcat=hcdconcat2.copy()\n",
    "hcdconcat.columns\n",
    "\n",
    "\n",
    "\n",
    "##commenting out KSADS because no longer in REDCap. Use Previous inventory\n",
    "##final cleanup of YES BUTS for known exceptions to BUT rule\n",
    "##this code commented out until last run AFTER study data finished completion\n",
    "##these guys were people whose mood batteries wiere missing so an ambiguous box was checked in the visit summary\n",
    "#hcdconcat.loc[(hcdconcat.Curated_KSADS_T=='YES BUT') & (hcdconcat.redcap_event=='V3'),'Curated_KSADS_T']='YES'\n",
    "#hcdconcat.loc[(hcdconcat.Curated_KSADS_T=='NO'),'Curated_KSADS_T']='NE PM'\n",
    "#hcdconcat.loc[(hcdconcat.Curated_KSADS_P=='NO'),'Curated_KSADS_P']='NE PM'\n",
    "#hcdconcat.loc[(hcdconcat.Curated_KSADS_MOOD_T=='NO'),'Curated_KSADS_MOOD_T']='NE PM'\n",
    "#hcdconcat.loc[(hcdconcat.Curated_KSADS_MOOD_P=='NO'),'Curated_KSADS_MOOD_P']='NE PM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hcdconcatbackup=hcdconcat.copy()\n",
    "#hcdconcat=hcdconcatbackup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NDA VARS\n",
    "#nda interview date\n",
    "hcdconcat['nda_interview_date']=pd.to_datetime(hcdconcat['event_date']) - pd.offsets.QuarterBegin(startingMonth=1)\n",
    "\n",
    "#nda age in months\n",
    "hcdconcat['nda_age'] = (\n",
    "        12 * (pd.to_datetime(hcdconcat['event_date']).dt.year - pd.to_datetime(hcdconcat.dob).dt.year) +\n",
    "        (pd.to_datetime(hcdconcat['event_date']).dt.month - pd.to_datetime(hcdconcat.dob).dt.month) +\n",
    "        (pd.to_datetime(hcdconcat['event_date']).dt.day - pd.to_datetime(hcdconcat.dob).dt.day) / 31)\n",
    "\n",
    "hcdconcat['nda_age']=hcdconcat.nda_age.apply(np.floor).round()\n",
    "#hcdconcat.nda_age=hcdconcat.nda_age.round() \n",
    "#HCAdf7['check_age']= HCAdf7.event_age.replace('',np.nan).astype(float)*12\n",
    "hcdconcat.sort_values(by='nda_age',ascending=False)[['subject','redcap_event','event_age','nda_age','event_date','nda_interview_date']]\n",
    "#merge in pedfinal by pseudo_guid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporarily add the two pedids for CC subs who used to be excluded\n",
    "pedfinal.head()\n",
    "hcdconcat=pd.merge(pedfinal,hcdconcat,how='right',on='psuedo_guid')#,indicator='bb')\n",
    "#HCAdf7.bb.value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedfinal.head()\n",
    "hcdconcat.columns\n",
    "hcdconcat.loc[hcdconcat.pedid.isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=hcdconcat[['dob','pedid','psuedo_guid','subject','redcap_event','nda_age','event_age','event_date','nda_interview_date']].copy()\n",
    "b=a.loc[a.nda_age.isnull()==True].copy()\n",
    "#b['years']=12 * (pd.to_datetime(b['event_date']).dt.year - pd.to_datetime(b.dob).dt.year)\n",
    "#b['months']=(pd.to_datetime(b['event_date']).dt.month - pd.to_datetime(b.dob).dt.month)\n",
    "#b['days']=(pd.to_datetime(b['event_date']).dt.day - pd.to_datetime(b.dob).dt.day) / 31\n",
    "#b['sumage']=b.years+b.months+b.days\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcdconcat.loc[hcdconcat.site=='MGH/Harvard','site']='Harvard'\n",
    "\n",
    "hcdconcat.loc[hcdconcat.DateFinishedTLBX.astype('str').str.contains('####'),'DateFinishedTLBX']=''\n",
    "hcdconcat.DateFinishedTLBX=pd.to_datetime(hcdconcat.DateFinishedTLBX)\n",
    "\n",
    "#clean up height and age\n",
    "hcdconcat.height=hcdconcat.height.str.replace('\"',\"'\").str.strip(\"'\").str.replace(' ','').str.replace(\"'\",'\"')\n",
    "hcdconcat.event_age=pd.to_numeric(hcdconcat['event_age'],errors='coerce').round(2)\n",
    "\n",
    "allcols=['pedid','nda_age','nda_interview_date','id', 'redcap_id_parent', 'psuedo_guid', 'DB_Source', 'HCAid', 'HCDid', 'subject','parent_at_visit', 'parent_at_V1',\n",
    "          'site', 'race', 'ethnic_group', 'M/F', \n",
    "       'height', 'weight','redcap_event_name', 'redcap_event', 'event_date','daysfromtime0',\n",
    "       'event_age', 'event_register','IntraDB', 'Curated_Eprime','Curated_KSADS_T',\n",
    "       'Curated_KSADS_MOOD_T', 'Curated_KSADS_P', \n",
    "       'Curated_KSADS_MOOD_P', \n",
    "       'Curated_PennCNP', 'Curated_Q', 'Curated_TLBX',  'Curated_TLBX_Parent', \n",
    "       'PIN', 'DateFinishedTLBX',\n",
    "       'ParentPIN','ParentDateFinishedTLBX', 'ParentChildTLBXdaydiff',\n",
    "       'misscat___3',\n",
    "       'misscat___9', 'misscat___5', 'misstoolbox', 'general_note',\n",
    "       'misscog___1', 'misscog___2', 'misscogq', 'misscogupen', 'missssaga',\n",
    "       'toolbox_complete', 'remote_toolbox_emotion_complete',\n",
    "       'misstoolbox___1', 'misstoolbox___2', 'misstoolbox___3', 'data_status',\n",
    "       'misstoolboxc', 'misstoolboxpc', 'misstoolboxpp', 'misscog___3',\n",
    "       'misscogdd', 'missksads___1', 'missksads___2', 'missksads_c',\n",
    "       'missksads_p']\n",
    "\n",
    "\n",
    "slimcols=['pedid','nda_age','nda_interview_date','id', 'redcap_id_parent', 'psuedo_guid', 'DB_Source', 'HCAid', 'HCDid', 'subject','parent_at_visit', 'parent_at_V1',\n",
    "          'site', 'race', 'ethnic_group', 'M/F', \n",
    "       'height', 'weight', 'redcap_event_name', 'redcap_event', 'daysfromtime0',\n",
    "       'event_age','IntraDB', 'Curated_Eprime','Curated_KSADS_T',\n",
    "       'Curated_KSADS_MOOD_T', 'Curated_KSADS_P', \n",
    "       'Curated_KSADS_MOOD_P',\n",
    "       'Curated_PennCNP', 'Curated_Q',  'Curated_TLBX',  'Curated_TLBX_Parent', \n",
    "       'PIN','ParentPIN', 'ParentChildTLBXdaydiff']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hcdconcat['event_age'].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in IntraDB variables and KSADS from Previous inventory.\n",
    "hcdconcat.head()\n",
    "oldinvent=\"/home/petra/Behavioral/Lifespan/PreRelease/PreRelease/oldinventories/HCD_Inventory_2022-04-12.csv\"\n",
    "OI=pd.read_csv(oldinvent)[['subject','redcap_event','Curated_KSADS_T','Curated_KSADS_MOOD_T', 'Curated_KSADS_P', 'Curated_KSADS_MOOD_P']]\n",
    "OI.head()\n",
    "\n",
    "#create an Imaging Flag\n",
    "intradbd=pd.read_csv('/home/petra/Behavioral/Lifespan/PreRelease/PreRelease/CCF_HCD_STG_20221122.csv')\n",
    "intradbd['subject']=intradbd.Subject\n",
    "intradbd['redcap_event']= intradbd['MR ID'].str.split('_', expand=True)[1]\n",
    "intradbd['IntraDB']='CCF_HCD_STG'\n",
    "\n",
    "intradbd.head()\n",
    "hcdconcat2=pd.merge(hcdconcat,OI,on=['subject','redcap_event'],how='left')\n",
    "\n",
    "hcdconcat3=pd.merge(hcdconcat2,intradbd[['subject','redcap_event','IntraDB']],on=['subject','redcap_event'],how='left')\n",
    "hcdconcat3.loc[(hcdconcat3.IntraDB.isnull()==True) & (hcdconcat3.redcap_event.isin(['V1','V2','V3'])),'IntraDB']=\"Behavioral Only\"\n",
    "#print(hcdconcat3.IntraDB.value_counts())\n",
    "#print(hcdconcat3.loc[hcdconcat3.IntraDB=='Behavioral Only'].redcap_event.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra cleanup for exceptions that weren't caught because of build-it-up style of coding (problems found as you go)\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_TLBX_Parent']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_TLBX']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_PennCNP']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_Q']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_KSADS_P']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_KSADS_T']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_KSADS_MOOD_P']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_KSADS_MOOD_T']='NE'\n",
    "hcdconcat3.loc[hcdconcat3.redcap_event.isin(['Covid','Covid2','F1']),'Curated_Eprime']='NE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For just \n",
    "ccin=['HCD0123824','HCD2059043']\n",
    "hcdconcat3.loc[(hcdconcat3.subject.isin(ccin)) & (hcdconcat3.Curated_KSADS_MOOD_T.isnull()==True),'Curated_KSADS_MOOD_T']='NE'\n",
    "hcdconcat3.loc[(hcdconcat3.subject.isin(ccin)) & (hcdconcat3.Curated_KSADS_MOOD_P.isnull()==True),'Curated_KSADS_MOOD_P']='NE'\n",
    "hcdconcat3.loc[(hcdconcat3.subject.isin(ccin)) & (hcdconcat3.Curated_KSADS_T.isnull()==True),'Curated_KSADS_T']='NE AGE'\n",
    "hcdconcat3.loc[(hcdconcat3.subject.isin(ccin)) & (hcdconcat3.Curated_KSADS_P.isnull()==True),'Curated_KSADS_P']='NE PM'\n",
    "\n",
    "hcdconcat3.loc[hcdconcat3.subject.isin(ccin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcdconcat3.IntraDB.value_counts()\n",
    "hcdconcat3.columns\n",
    "hcdconcat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export a few useful forms of the inventory - slim goes up to the PreRelease folder\n",
    "hcdconcat3[allcols].rename(columns={'id':'REDCap_id','redcap_id_parent':'REDCap_id_parent','psuedo_guid':'pseudo_guid'}).to_csv('HCD_AllSources_'+snapshotdate+'.csv',index=False)\n",
    "hcdconcat3[slimcols].rename(columns={'id':'REDCap_id','redcap_id_parent':'REDCap_id_parent','psuedo_guid':'pseudo_guid'}).to_csv('HCD_AllSourcesSlim_' + snapshotdate + '.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcdconcat4=hcdconcat3.copy()\n",
    "hcdconcat4['anytlbx']='NO'\n",
    "hcdconcat4.loc[(hcdconcat4.Curated_TLBX=='YES') | (hcdconcat4.Curated_TLBX_Parent=='YES'),'anytlbx']='YES'\n",
    "\n",
    "hcdconcat4.anytlbx.value_counts()\n",
    "hcdconcat4['ageyears']=hcdconcat4.event_age.apply(np.floor).round()\n",
    "hcdconcat4=hcdconcat4.loc[hcdconcat4.redcap_event.isin(['V1','V2','V3'])].copy()\n",
    "pd.DataFrame(pd.crosstab(hcdconcat4['ageyears'], [hcdconcat4.anytlbx])).to_csv('crosstabsDeanna.csv',index=True)\n",
    "hcdconcat4=hcdconcat4.loc[hcdconcat4.IntraDB=='CCF_HCD_STG'].copy()\n",
    "pd.DataFrame(pd.crosstab(hcdconcat4['ageyears'], [hcdconcat4.anytlbx])).to_csv('crosstabsDeanna2.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hcdconcat3.loc[(hcdconcat3.redcap_event.isin(['V1','V2','V3']))].redcap_event.value_counts())\n",
    "print(hcdconcat3.loc[(hcdconcat3.redcap_event.isin(['V1','V2','V3'])) & (hcdconcat3.IntraDB=='CCF_HCD_STG')].redcap_event.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missingness Stats for TOOLBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#print(hcdconcat3[['site','redcap_event','Curated_TLBX_Parent','index']].loc[hcdconcat.redcap_event.isin(['V1','V2','V3'])].groupby(['site']).count())\n",
    "#print(hcdconcat3[['site','redcap_event','Curated_TLBX_Parent','index']].loc[hcdconcat.Curated_TLBX_Parent=='NO'].groupby(['site']).count())\n",
    "orig_stdout = sys.stdout\n",
    "f = open(os.path.join('HCD_Missingness_Report_'+snapshotdate+'.txt'),'w')\n",
    "sys.stdout = f\n",
    "\n",
    "a=hcdconcat3.copy()#.groupby(['site']).count())\n",
    "a['datediff']=(pd.to_datetime(a['event_date'])-datetime.datetime.today()).dt.days\n",
    "t0=a.loc[a.datediff.abs()>14].copy()\n",
    "\n",
    "print('********************************************************************************')\n",
    "print('DATA UNDER PARENT ID ***********************************************************')\n",
    "for curatedstar in['Curated_TLBX_Parent']:\n",
    "    print('********************************************************************************')\n",
    "    print(curatedstar)\n",
    "    #print(hcdconcat[['site','redcap_event',curatedstar,'index']].loc[hcdconcat.redcap_event.isin(['V1','V2','V3'])].groupby(['site','redcap_event',curatedstar]).count())\n",
    "\n",
    "    #parents\n",
    "    t1=t0.loc[~(t0[curatedstar].isin(['NE AGE','NE']))][['site','redcap_event',curatedstar,'index']]\n",
    "    totals=pd.DataFrame(t1.loc[t1.redcap_event.isin(['V1','V2','V3'])].groupby(['site']).count())\n",
    "    #totals=pd.DataFrame(hcdconcat[['site','redcap_event',curatedstar,'index']].loc[hcdconcat.redcap_event.isin(['V1','V2','V3'])].groupby(['site']).count())\n",
    "    missings=pd.DataFrame(t1[['site','redcap_event',curatedstar,'index']].loc[hcdconcat[curatedstar]=='NO'].groupby(['site']).count())\n",
    "\n",
    "    totals['Total_Parents']=totals[curatedstar]\n",
    "    missings['Missing_Parents']=missings[curatedstar]\n",
    "\n",
    "    statsparents=pd.concat([totals[['Total_Parents']],missings[['Missing_Parents']]],axis=1,sort=True)\n",
    "    statsparents['PCT_Missing']=round(((statsparents.Missing_Parents)/(statsparents.Total_Parents))*100.0,1)\n",
    "    print(statsparents)\n",
    "\n",
    "    #statsparents.to_csv('statsparents.csv')\n",
    "\n",
    "print()\n",
    "print('********************************************************************************')\n",
    "print('DATA UNDER CHILD ID ************************************************************')\n",
    "for curatedstar in['Curated_TLBX','Curated_KSADS_T','Curated_KSADS_MOOD_T','Curated_KSADS_P','Curated_KSADS_MOOD_P','Curated_PennCNP','Curated_Eprime','Curated_Q']:\n",
    "    print('********************************************************************************')\n",
    "    print(curatedstar)\n",
    "\n",
    "    #subjects\n",
    "    t1=t0.loc[~(t0[curatedstar].isin(['NE AGE','NE']))][['site','redcap_event',curatedstar,'index']]\n",
    "    totals=pd.DataFrame(t1.loc[t1.redcap_event.isin(['V1','V2','V3'])].groupby(['site']).count())\n",
    "\n",
    "    #totals=pd.DataFrame(hcdconcat[['site','redcap_event',curatedstar,'index']].loc[hcdconcat.redcap_event.isin(['V1','V2','V3'])].groupby(['site']).count())\n",
    "    missings=pd.DataFrame(t1[['site','redcap_event',curatedstar,'index']].loc[hcdconcat[curatedstar]=='NO'].groupby(['site']).count())\n",
    "\n",
    "    totals['Total_Subjects']=totals[curatedstar]\n",
    "    missings['Missing_Subjects']=missings[curatedstar]\n",
    "\n",
    "    stats=pd.concat([totals[['Total_Subjects']],missings[['Missing_Subjects']]],axis=1,sort=True)\n",
    "    stats['PCT_Missing']=round(((stats.Missing_Subjects)/(stats.Total_Subjects))*100.0,1)\n",
    "    print(stats)\n",
    "    #stats.to_csv('statschild.csv')\n",
    "    \n",
    "    \n",
    "sys.stdout = orig_stdout\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "##TLBX is for toolbox data cleaning, specifically\n",
    "HCAexpectedTLBX=HCAdf8.loc[HCAdf8.redcap_event.isin(['V1','V2','CR'])].copy()\n",
    "\n",
    "#HCAexpectedTLBX.loc[HCAexpectedTLBX.site=='MGH/Harvard','site']='MGH'\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open(os.path.join('HCA_Missingness_Report_'+snapshotdate+'.txt'),'w')\n",
    "sys.stdout = f\n",
    "\n",
    "#subjects\n",
    "for curatedstar in['Curated_TLBX','Curated_Q','Curated_PennCNP','Curated_SSAGA']:\n",
    "    print('***********************************************')\n",
    "    print(curatedstar)\n",
    "    NOs=HCAexpectedTLBX.loc[(HCAexpectedTLBX[curatedstar]=='NO') & (HCAexpectedTLBX.redcap_event.isin(['V1','V2','CR']))]\n",
    "    ##print(HCAexpectedTLBX[['site','redcap_event',curatedstar,'index']].groupby(['site','redcap_event',curatedstar]).count())\n",
    "    Nostring=NOs[['site','redcap_event',curatedstar,'index']].groupby(['site','redcap_event',curatedstar]).count()\n",
    "    #print(str(Nostring))\n",
    "    #print('*********************')\n",
    "\n",
    "    a=HCAexpectedTLBX[['site','redcap_event',curatedstar,'index','event_date']].loc[(HCAexpectedTLBX.redcap_event.isin(['V1','V2','CR']))].copy()#.groupby(['site']).count())\n",
    "    a['datediff']=(pd.to_datetime(a['event_date'])-datetime.datetime.today()).dt.days\n",
    "    b=a.loc[a.datediff.abs()>14].copy()\n",
    "\n",
    "    totals=pd.DataFrame(b[['site','redcap_event',curatedstar,'index']].loc[b.redcap_event.isin(['V1','V2','CR'])].groupby(['site']).count())\n",
    "    missings=pd.DataFrame(b[['site','redcap_event',curatedstar,'index']].loc[b[curatedstar]=='NO'].groupby(['site']).count())\n",
    "\n",
    "    totals['Total_Subjects']=totals[curatedstar]\n",
    "    missings['Missing_Subjects']=missings[curatedstar]\n",
    "\n",
    "    stats=pd.concat([totals[['Total_Subjects']],missings[['Missing_Subjects']]],axis=1,sort=True)\n",
    "    stats['PCT_Missing']=round(100*(stats.Missing_Subjects)/(stats.Total_Subjects),1)\n",
    "\n",
    "    print(stats)\n",
    "#stats.to_csv('statshca.csv')\n",
    "sys.stdout = orig_stdout\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout = orig_stdout\n",
    "#f.close()\n",
    "#orig_stdout\n",
    "#sys.stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "a=HCAexpectedTLBX[['site','redcap_event','Curated_TLBX','index','event_date']].loc[(HCAexpectedTLBX.redcap_event.isin(['V1','V2','CR']))]#.groupby(['site']).count())\n",
    "a['datediff']=(pd.to_datetime(a['event_date'])-datetime.datetime.today()).dt.days\n",
    "b=a.loc[a.datediff.abs()>7]\n",
    "#b\n",
    "#a.loc[a.event_date < snapshotdate] \n",
    "#a['datediff']=(a.event_date-snapshotdate).dt.days\n",
    "#a['datediff']=(pd.to_datetime(a['event_date'])-pd.to_datetime(snapshotdate)).dt.days\n",
    "#togetherinventory11['ParentChildTLBXdaydiff']=(togetherinventory11.ParentDateFinishedTLBX - togetherinventory11.ChildDateFinishedTLBX).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.datediff.abs()<7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDA_submissions",
   "language": "python",
   "name": "nda_submissions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
